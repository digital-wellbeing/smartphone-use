<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Analysis Study 1 | Analysis Report</title>
  <meta name="description" content="Analysis report detailing alls steps from data processing to final analyses." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Analysis Study 1 | Analysis Report" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/digital-wellbeing/smartphone-use" />
  
  <meta property="og:description" content="Analysis report detailing alls steps from data processing to final analyses." />
  <meta name="github-repo" content="digital-wellbeing/smartphone-use" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Analysis Study 1 | Analysis Report" />
  
  <meta name="twitter:description" content="Analysis report detailing alls steps from data processing to final analyses." />
  

<meta name="author" content="Niklas Johannes" />


<meta name="date" content="2021-01-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="descriptives-and-visualizations-study-1.html"/>
<link rel="next" href="synthesis-study-1.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Analysis Report</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Study 1</b></span></li>
<li class="chapter" data-level="1" data-path="setting-up-study1.html"><a href="setting-up-study1.html"><i class="fa fa-check"></i><b>1</b> Setting up</a></li>
<li class="chapter" data-level="2" data-path="data-processing-study1.html"><a href="data-processing-study1.html"><i class="fa fa-check"></i><b>2</b> Data processing Study 1</a><ul>
<li class="chapter" data-level="2.1" data-path="data-processing-study1.html"><a href="data-processing-study1.html#personality-data"><i class="fa fa-check"></i><b>2.1</b> Personality data</a></li>
<li class="chapter" data-level="2.2" data-path="data-processing-study1.html"><a href="data-processing-study1.html#diary-data"><i class="fa fa-check"></i><b>2.2</b> Diary data</a></li>
<li class="chapter" data-level="2.3" data-path="data-processing-study1.html"><a href="data-processing-study1.html#screen-time-data"><i class="fa fa-check"></i><b>2.3</b> Screen time data</a></li>
<li class="chapter" data-level="2.4" data-path="data-processing-study1.html"><a href="data-processing-study1.html#merge-data-sets"><i class="fa fa-check"></i><b>2.4</b> Merge data sets</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="descriptives-and-visualizations-study-1.html"><a href="descriptives-and-visualizations-study-1.html"><i class="fa fa-check"></i><b>3</b> Descriptives and Visualizations Study 1</a><ul>
<li class="chapter" data-level="3.1" data-path="descriptives-and-visualizations-study-1.html"><a href="descriptives-and-visualizations-study-1.html#overview"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="descriptives-and-visualizations-study-1.html"><a href="descriptives-and-visualizations-study-1.html#meta-level"><i class="fa fa-check"></i><b>3.2</b> Meta-level</a></li>
<li class="chapter" data-level="3.3" data-path="descriptives-and-visualizations-study-1.html"><a href="descriptives-and-visualizations-study-1.html#person-level"><i class="fa fa-check"></i><b>3.3</b> Person-level</a></li>
<li class="chapter" data-level="3.4" data-path="descriptives-and-visualizations-study-1.html"><a href="descriptives-and-visualizations-study-1.html#app-level"><i class="fa fa-check"></i><b>3.4</b> App-level</a></li>
<li class="chapter" data-level="3.5" data-path="descriptives-and-visualizations-study-1.html"><a href="descriptives-and-visualizations-study-1.html#day-level"><i class="fa fa-check"></i><b>3.5</b> Day level</a></li>
<li class="chapter" data-level="3.6" data-path="descriptives-and-visualizations-study-1.html"><a href="descriptives-and-visualizations-study-1.html#plots-for-paper"><i class="fa fa-check"></i><b>3.6</b> Plots for paper</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="analysis-study-1.html"><a href="analysis-study-1.html"><i class="fa fa-check"></i><b>4</b> Analysis Study 1</a><ul>
<li class="chapter" data-level="4.1" data-path="analysis-study-1.html"><a href="analysis-study-1.html#research-questions"><i class="fa fa-check"></i><b>4.1</b> Research questions</a></li>
<li class="chapter" data-level="4.2" data-path="analysis-study-1.html"><a href="analysis-study-1.html#data-preparation"><i class="fa fa-check"></i><b>4.2</b> Data preparation</a></li>
<li class="chapter" data-level="4.3" data-path="analysis-study-1.html"><a href="analysis-study-1.html#do-trait-variables-predict-social-media-use-and-accuracy"><i class="fa fa-check"></i><b>4.3</b> Do trait variables predict social media use and accuracy?</a><ul>
<li class="chapter" data-level="4.3.1" data-path="analysis-study-1.html"><a href="analysis-study-1.html#model-1-trait-variables-predicting-objective-use"><i class="fa fa-check"></i><b>4.3.1</b> Model 1: Trait variables predicting objective use</a></li>
<li class="chapter" data-level="4.3.2" data-path="analysis-study-1.html"><a href="analysis-study-1.html#model-2-trait-variables-predicting-subjective-use"><i class="fa fa-check"></i><b>4.3.2</b> Model 2: Trait variables predicting subjective use</a></li>
<li class="chapter" data-level="4.3.3" data-path="analysis-study-1.html"><a href="analysis-study-1.html#model-3-trait-variables-predicting-accuracy"><i class="fa fa-check"></i><b>4.3.3</b> Model 3: Trait variables predicting accuracy</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="analysis-study-1.html"><a href="analysis-study-1.html#do-state-i.e.-day-level-variables-predict-social-media-use-and-accuracy"><i class="fa fa-check"></i><b>4.4</b> Do state (i.e., day-level) variables predict social media use and accuracy?</a><ul>
<li class="chapter" data-level="4.4.1" data-path="analysis-study-1.html"><a href="analysis-study-1.html#model-4-state-variables-predicting-objective-use"><i class="fa fa-check"></i><b>4.4.1</b> Model 4: State variables predicting objective use</a></li>
<li class="chapter" data-level="4.4.2" data-path="analysis-study-1.html"><a href="analysis-study-1.html#model-5-state-variables-predicting-subjective-use"><i class="fa fa-check"></i><b>4.4.2</b> Model 5: State variables predicting subjective use</a></li>
<li class="chapter" data-level="4.4.3" data-path="analysis-study-1.html"><a href="analysis-study-1.html#model-6-state-variables-predicting-accuracy"><i class="fa fa-check"></i><b>4.4.3</b> Model 6: State variables predicting accuracy</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="analysis-study-1.html"><a href="analysis-study-1.html#does-social-media-use-predict-well-being"><i class="fa fa-check"></i><b>4.5</b> Does social media use predict well-being?</a><ul>
<li class="chapter" data-level="4.5.1" data-path="analysis-study-1.html"><a href="analysis-study-1.html#model-7-objective-use-predicting-well-being"><i class="fa fa-check"></i><b>4.5.1</b> Model 7: Objective use predicting well-being</a></li>
<li class="chapter" data-level="4.5.2" data-path="analysis-study-1.html"><a href="analysis-study-1.html#model-8-subjective-use-predicting-well-being"><i class="fa fa-check"></i><b>4.5.2</b> Model 8: Subjective use predicting well-being</a></li>
<li class="chapter" data-level="4.5.3" data-path="analysis-study-1.html"><a href="analysis-study-1.html#model-9-accuracy-predicting-well-being"><i class="fa fa-check"></i><b>4.5.3</b> Model 9: Accuracy predicting well-being</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="synthesis-study-1.html"><a href="synthesis-study-1.html"><i class="fa fa-check"></i><b>5</b> Synthesis Study 1</a><ul>
<li class="chapter" data-level="5.1" data-path="synthesis-study-1.html"><a href="synthesis-study-1.html#personality-on-smartphone-use-trait"><i class="fa fa-check"></i><b>5.1</b> Personality on smartphone use (trait)</a></li>
<li class="chapter" data-level="5.2" data-path="synthesis-study-1.html"><a href="synthesis-study-1.html#experiences-on-smartphone-use-state"><i class="fa fa-check"></i><b>5.2</b> Experiences on smartphone use (state)</a></li>
<li class="chapter" data-level="5.3" data-path="synthesis-study-1.html"><a href="synthesis-study-1.html#smartphone-use-on-well-being-state"><i class="fa fa-check"></i><b>5.3</b> Smartphone use on well-being (state)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analysis Report</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="analysis-study-1" class="section level1">
<h1><span class="header-section-number">4</span> Analysis Study 1</h1>
<p>I move on to the analyses.
We have about a dozen models to run.
All of these models should take into account that the data are nested (in participants and days).
That means quite complex model structures, especially when we have many predictors.
The <code>lme4</code> package can handle such multi-level models, but in my experience suffers from many convergence issues that a Bayesian approach (i.e., the <code>brms</code> package) can handle better [paper on convergence comparison].
Moreover, corrections for multiple comparisons are less of a problem with Bayesian models.
Last, although the models here are mostly exploratory, we can still incorporate prior knowledge from the literature (and common sense about our variables).</p>
<div id="research-questions" class="section level2">
<h2><span class="header-section-number">4.1</span> Research questions</h2>
<p>We have a total of 9 research questions.
I divide them in three blocks:</p>
<ol style="list-style-type: decimal">
<li>To what extent do specific person-level variables such as personality and motivational factors shape the accuracy of social media time engagement?</li>
<li>To what extent do subjective experiences such as mood predict and or interact with person-level factors to shape the accuracy of social media time engagement?</li>
<li>What are the unique relations relating objective and subjective engagement to well-being outcomes?</li>
</ol>
<p>Each of those questions comes with a number of models.
I’ll structure the analysis section according to those blocks.</p>
</div>
<div id="data-preparation" class="section level2">
<h2><span class="header-section-number">4.2</span> Data preparation</h2>
<p>I processed the <code>study1</code> data set in previous sections.
Specifying priors on the untransformed variables can be tough.
In some analyses (e.g., predicting social media use) I’ll use centered predictors to make it easier to interpret the intercept.
In other analyses (e.g., predicting error), I want to standardize outcomes and predictors of interest because standardized variables make it easier to choose sensible priors, especially because we can use standardized effect sizes reported in the literature.
Standardizing also makes it easier to interpret the effect sizes.</p>
<p>First, I transform all variables of interest (into new variables).</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="analysis-study-1.html#cb62-1"></a><span class="kw">load</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;workspace_study1.RData&quot;</span>))</span>
<span id="cb62-2"><a href="analysis-study-1.html#cb62-2"></a></span>
<span id="cb62-3"><a href="analysis-study-1.html#cb62-3"></a>study1 &lt;-<span class="st"> </span></span>
<span id="cb62-4"><a href="analysis-study-1.html#cb62-4"></a><span class="st">  </span>study1 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb62-5"><a href="analysis-study-1.html#cb62-5"></a><span class="st">  </span><span class="co"># center personality variables</span></span>
<span id="cb62-6"><a href="analysis-study-1.html#cb62-6"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb62-7"><a href="analysis-study-1.html#cb62-7"></a>    <span class="kw">across</span>(</span>
<span id="cb62-8"><a href="analysis-study-1.html#cb62-8"></a>      <span class="kw">c</span>(</span>
<span id="cb62-9"><a href="analysis-study-1.html#cb62-9"></a>        autonomy_state<span class="op">:</span>relatedness_state,</span>
<span id="cb62-10"><a href="analysis-study-1.html#cb62-10"></a>        satisfied<span class="op">:</span>enjoyable,</span>
<span id="cb62-11"><a href="analysis-study-1.html#cb62-11"></a>        autonomy_trait<span class="op">:</span>openness</span>
<span id="cb62-12"><a href="analysis-study-1.html#cb62-12"></a>      ),</span>
<span id="cb62-13"><a href="analysis-study-1.html#cb62-13"></a>      <span class="op">~</span><span class="st"> </span><span class="kw">scale</span>(.x, <span class="dt">center =</span> <span class="ot">TRUE</span>, <span class="dt">scale =</span> <span class="ot">FALSE</span>),</span>
<span id="cb62-14"><a href="analysis-study-1.html#cb62-14"></a>      <span class="dt">.names =</span> <span class="st">&quot;{col}_c&quot;</span> <span class="co"># add &quot;_c&quot; suffix to new variables for &quot;centered&quot;</span></span>
<span id="cb62-15"><a href="analysis-study-1.html#cb62-15"></a>    )</span>
<span id="cb62-16"><a href="analysis-study-1.html#cb62-16"></a>  )</span></code></pre></div>
<p>Next, let’s have a look of how many <code>NA</code>s there are per variable.
Table <a href="analysis-study-1.html#tab:missings-study1">4.1</a> shows that missing values aren’t a big problem.
Pickups is the only variable with many missing values, but pickups aren’t a central variable in our research questions.</p>
<table>
<caption><span id="tab:missings-study1">Table 4.1: </span>Missing values per variable (column)</caption>
<thead>
<tr class="header">
<th align="left">name</th>
<th align="right">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">social_media_subjective</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">pickups_subjective</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">notifications_subjective</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">social_media_objective</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">error</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">pickups_objective</td>
<td align="right">28</td>
</tr>
<tr class="odd">
<td align="left">weekly_notifications</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">well_being_state</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">autonomy_state</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">competence_state</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">relatedness_state</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">satisfied</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">boring</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">stressful</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">enjoyable</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">autonomy_trait</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">competence_trait</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">relatedness_trait</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">extraversion</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">agreeableness</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">conscientiousness</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">neuroticism</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">openness</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
</div>
<div id="do-trait-variables-predict-social-media-use-and-accuracy" class="section level2">
<h2><span class="header-section-number">4.3</span> Do trait variables predict social media use and accuracy?</h2>
<p>Our first research question asks whether personality traits and trait motivations predict the accuracy of social media time engagement.
Specifically, we have three models that address the following sub-questions:</p>
<ol style="list-style-type: decimal">
<li>Do person-level variables predict objective-only engagement?</li>
<li>Do person-level variables predict subjective-only engagement?</li>
<li>Do person-level variables predict accuracy?</li>
</ol>
<p>I’ll construct a model for each of those three questions.
Our dependent variables are clear-cut: <code>social_media_objective</code>, <code>social_media_subjective</code>, and <code>error</code>.</p>
<p>Our predictors will be variables on the person-level, so trait/personality variables: the Big Five and the three self-determination motivations.</p>
<div id="model-1-trait-variables-predicting-objective-use" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Model 1: Trait variables predicting objective use</h3>
<p>First, I choose sensible priors.
There’s some literature out there on Big Five and smartphone use, as well as motivations and smartphone use.
If we only knew the mean and variance of the social media estimates, a Gaussian distribution would be most appropriate.
However, we do know more than just those two parameters.
Namely, we know that the scale is continuous (i.e., time) and cannot be less than zero.
Also, if we look at the distribution of time on an activity, the variance usually increases with the mean.
Therefore, a gamma distribution appears more adequate to me.</p>
<p>That means the models will use a log-link, which makes it hard to have an intuition about prior distributions (at least for me).
Thus, I follow the recommendations of McElreath and simulate the priors.</p>
<ul>
<li>For the intercept, we can look at previous research.
For example, this <a href="https://www.sciencedirect.com/science/article/abs/pii/S1071581919300473">paper</a> has average phone use times of about two hours per participant per day.
Here, we only looked at social media use, so as a guess-timate with reasonable uncertainty, I’ll choose a lognormal distribution with a meanlog of 4.5 and a meansd of 0.8. See the upper left panel of Figure <a href="analysis-study-1.html#fig:simulate-priors-model1-study1">4.1</a>. That intercept has mots its value below two hours, but allows substantial skew for a couple of heavy users.</li>
<li>For the shape of the gamma distribution, I also played around and settled on one that somewhat resembles our assumptions on the intercept, such that the majority of values will be below five hours with a couple of heavy users (see left side upper panel).</li>
<li>For the Big Five fixed effects, this <a href="https://www.liebertpub.com/doi/full/10.1089/cyber.2019.0744">paper</a> predicted social media use with the Big Five over two time period in a longitudinal design. They found that only neuroticism was related to social media use, but that effect was extremely small (<span class="math inline">\(\beta\)</span> = .028). None of the other effects were large. Therefore, I’ll use rather flat, weakly regularizing priors for those effects.
In <a href="analysis-study-1.html#fig:simulate-priors-model1-study1">4.1</a>, lower panel, I’ll use the prior on the left, because it’s skeptical, but regularizing.
The one on the right might be too optimistic by suggesting a small positive effect.</li>
<li>For basic psychological needs, there’s quite some literature on these needs and pathological smartphone use (“smartphone addiction”). However, there’s little info we could use for priors, so I’ll just go with the same prior as for the Big Five.
See the top right of the Figure below.</li>
<li>For all other parameters, I’ll take the <code>brms</code> default priors.</li>
</ul>
Credit for the code for the figures goes to <a href="https://bookdown.org/connect/#/apps/4857/access">Solomon Kurz</a>.
<div class="figure"><span id="fig:simulate-priors-model1-study1"></span>
<img src="analysis_report_files/figure-html/simulate-priors-model1-study1-1.png" alt="Prior simmulations for Model 1" width="672" />
<p class="caption">
Figure 4.1: Prior simmulations for Model 1
</p>
</div>
<p>Let’s set those priors we simulated above.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="analysis-study-1.html#cb63-1"></a>priors_model1 &lt;-<span class="st"> </span></span>
<span id="cb63-2"><a href="analysis-study-1.html#cb63-2"></a><span class="st">  </span><span class="kw">c</span>(</span>
<span id="cb63-3"><a href="analysis-study-1.html#cb63-3"></a>    <span class="co"># intercept</span></span>
<span id="cb63-4"><a href="analysis-study-1.html#cb63-4"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="fl">4.5</span>, <span class="fl">0.8</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb63-5"><a href="analysis-study-1.html#cb63-5"></a>    </span>
<span id="cb63-6"><a href="analysis-study-1.html#cb63-6"></a>    <span class="co"># prior on effects</span></span>
<span id="cb63-7"><a href="analysis-study-1.html#cb63-7"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.1</span>), <span class="dt">class =</span> b),</span>
<span id="cb63-8"><a href="analysis-study-1.html#cb63-8"></a>    </span>
<span id="cb63-9"><a href="analysis-study-1.html#cb63-9"></a>    <span class="co"># all other effects</span></span>
<span id="cb63-10"><a href="analysis-study-1.html#cb63-10"></a>    <span class="kw">prior</span>(<span class="kw">gamma</span>(<span class="fl">2.5</span>, <span class="dv">100</span>), <span class="dt">class =</span> shape)</span>
<span id="cb63-11"><a href="analysis-study-1.html#cb63-11"></a>  )</span></code></pre></div>
<p>Alright, time to run the model.
Luckily, none of these variables have missing values, so I won’t need to model missings in this model.
Note that I ran the block below once and stored the model.
Those fit objects are too large for Github, so you can download them here [give Onedrive link].
Also, note that I add a constant to the social media use variable, because there’s a single zero in that variable, which doesn’t warrant a mixture model where we give zeros their own distribution.</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="analysis-study-1.html#cb64-1"></a>model1 &lt;-<span class="st"> </span></span>
<span id="cb64-2"><a href="analysis-study-1.html#cb64-2"></a><span class="st">  </span><span class="kw">brm</span>(</span>
<span id="cb64-3"><a href="analysis-study-1.html#cb64-3"></a>    <span class="dt">data =</span> study1,</span>
<span id="cb64-4"><a href="analysis-study-1.html#cb64-4"></a>    <span class="dt">family =</span> <span class="kw">Gamma</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>),</span>
<span id="cb64-5"><a href="analysis-study-1.html#cb64-5"></a>    <span class="dt">prior =</span> priors_model1,</span>
<span id="cb64-6"><a href="analysis-study-1.html#cb64-6"></a>    social_media_objective <span class="op">+</span><span class="st"> </span><span class="fl">1e-6</span> <span class="op">~</span></span>
<span id="cb64-7"><a href="analysis-study-1.html#cb64-7"></a><span class="st">      </span><span class="dv">1</span> <span class="op">+</span></span>
<span id="cb64-8"><a href="analysis-study-1.html#cb64-8"></a><span class="st">      </span>openness_c <span class="op">+</span></span>
<span id="cb64-9"><a href="analysis-study-1.html#cb64-9"></a><span class="st">      </span>conscientiousness_c <span class="op">+</span></span>
<span id="cb64-10"><a href="analysis-study-1.html#cb64-10"></a><span class="st">      </span>extraversion_c <span class="op">+</span></span>
<span id="cb64-11"><a href="analysis-study-1.html#cb64-11"></a><span class="st">      </span>agreeableness_c <span class="op">+</span></span>
<span id="cb64-12"><a href="analysis-study-1.html#cb64-12"></a><span class="st">      </span>neuroticism_c <span class="op">+</span></span>
<span id="cb64-13"><a href="analysis-study-1.html#cb64-13"></a><span class="st">      </span>competence_trait_c <span class="op">+</span></span>
<span id="cb64-14"><a href="analysis-study-1.html#cb64-14"></a><span class="st">      </span>relatedness_trait_c <span class="op">+</span></span>
<span id="cb64-15"><a href="analysis-study-1.html#cb64-15"></a><span class="st">      </span>autonomy_trait_c <span class="op">+</span></span>
<span id="cb64-16"><a href="analysis-study-1.html#cb64-16"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id) <span class="op">+</span></span>
<span id="cb64-17"><a href="analysis-study-1.html#cb64-17"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>day),</span>
<span id="cb64-18"><a href="analysis-study-1.html#cb64-18"></a>    <span class="dt">iter =</span> <span class="dv">5000</span>,</span>
<span id="cb64-19"><a href="analysis-study-1.html#cb64-19"></a>    <span class="dt">warmup =</span> <span class="dv">2000</span>,</span>
<span id="cb64-20"><a href="analysis-study-1.html#cb64-20"></a>    <span class="dt">chains =</span> <span class="dv">4</span>,</span>
<span id="cb64-21"><a href="analysis-study-1.html#cb64-21"></a>    <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb64-22"><a href="analysis-study-1.html#cb64-22"></a>    <span class="dt">seed =</span> <span class="dv">42</span>,</span>
<span id="cb64-23"><a href="analysis-study-1.html#cb64-23"></a>    <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>),</span>
<span id="cb64-24"><a href="analysis-study-1.html#cb64-24"></a>    <span class="dt">file =</span> <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model1_study1&quot;</span>)</span>
<span id="cb64-25"><a href="analysis-study-1.html#cb64-25"></a>  )</span></code></pre></div>
Let’s inspect the traceplots.
Overall, they look fine and the chains seem to have mixed well, see (Figure <a href="#fig:inspect-model1-study1"><strong>??</strong></a>).
The residual standard deviation around the day grouping doesn’t look ideal though.
Variation between days wasn’t that great, so the model estimates quite a lot variances that are close to zero.
We could remove the day grouping, but I think we have theoretical reasons to keep it, namely to account for all known sources of variation.
<div class="figure"><span id="fig:inspect-model1-study1-1"></span>
<img src="analysis_report_files/figure-html/inspect-model1-study1-1.png" alt="Traceplots and posterior distributions for Model 1" width="672" />
<p class="caption">
Figure 4.2: Traceplots and posterior distributions for Model 1
</p>
</div>
<div class="figure"><span id="fig:inspect-model1-study1-2"></span>
<img src="analysis_report_files/figure-html/inspect-model1-study1-2.png" alt="Traceplots and posterior distributions for Model 1" width="672" />
<p class="caption">
Figure 4.3: Traceplots and posterior distributions for Model 1
</p>
</div>
<div class="figure"><span id="fig:inspect-model1-study1-3"></span>
<img src="analysis_report_files/figure-html/inspect-model1-study1-3.png" alt="Traceplots and posterior distributions for Model 1" width="672" />
<p class="caption">
Figure 4.4: Traceplots and posterior distributions for Model 1
</p>
</div>
The posterior predictive distribution (Figure <a href="analysis-study-1.html#fig:ppc-model1-study1">4.5</a>) shows that the model does an okay job in predicting our outcome, with little indication of overfitting.
If anything, it looks like the model somewhat underestimates the social media time of users.
Then again, the LOO-PIT graphs show that the model could be better, possibly because it doesn’t do the best job in predicting the majority of cases (i.e., the underestimate).
<div class="figure"><span id="fig:ppc-model1-study1"></span>
<img src="analysis_report_files/figure-html/ppc-model1-study1-1.png" alt="Posterior predictive checks for Model 1" width="672" />
<p class="caption">
Figure 4.5: Posterior predictive checks for Model 1
</p>
</div>
<p>Let’s also check for potentially influential values.
None are tagged as influential, which increases my trust in the model.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="analysis-study-1.html#cb65-1"></a><span class="kw">loo</span>(model1)</span></code></pre></div>
<pre><code>## 
## Computed from 12000 by 431 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -2474.7 15.2
## p_loo        21.2  2.5
## looic      4949.4 30.5
## ------
## Monte Carlo SE of elpd_loo is 0.1.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     426   98.8%   5202      
##  (0.5, 0.7]   (ok)         5    1.2%   532       
##    (0.7, 1]   (bad)        0    0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>Alright, time to look at the summary: neuroticism and competence are the only predictors whose posterior distribution isn’t centered on zero.
That said, we cannot be 95% certain the true value doesn’t contain zero.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="analysis-study-1.html#cb67-1"></a><span class="kw">summary</span>(model1, <span class="dt">priors =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>##  Family: gamma 
##   Links: mu = log; shape = identity 
## Formula: social_media_objective + 1e-06 ~ 1 + openness_c + conscientiousness_c + extraversion_c + agreeableness_c + neuroticism_c + competence_trait_c + relatedness_trait_c + autonomy_trait_c + (1 | id) + (1 | day) 
##    Data: study1 (Number of observations: 431) 
## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Priors: 
## b ~ normal(0, 0.1)
## Intercept ~ normal(4.5, 0.8)
## sd ~ student_t(3, 0, 2.5)
## shape ~ gamma(2.5, 100)
## 
## Group-Level Effects: 
## ~day (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.07      0.07     0.00     0.25 1.00     5550     5242
## 
## ~id (Number of levels: 95) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.49      0.08     0.34     0.64 1.00     3514     5799
## 
## Population-Level Effects: 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept               4.81      0.08     4.66     4.96 1.00     5471     6527
## openness_c             -0.01      0.08    -0.17     0.15 1.00    11136     9744
## conscientiousness_c     0.01      0.08    -0.15     0.17 1.00     8984     8356
## extraversion_c          0.07      0.07    -0.06     0.21 1.00     8190     8394
## agreeableness_c        -0.07      0.08    -0.22     0.09 1.00    10473     9765
## neuroticism_c           0.11      0.08    -0.05     0.27 1.00     9884     9423
## competence_trait_c     -0.11      0.07    -0.26     0.04 1.00     8081     8841
## relatedness_trait_c    -0.00      0.06    -0.13     0.12 1.00     7910     8576
## autonomy_trait_c       -0.03      0.07    -0.16     0.10 1.00     7789     9054
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## shape     1.32      0.09     1.14     1.51 1.00     9116     7480
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
The effects plot (Figure <a href="analysis-study-1.html#fig:effects-model1-study1">4.6</a>) shows that visually, but also shows that the model does a fine job in describing the data, given the relatively (at least on the log scale) narrow 95% credible interval.
Overall, there’s little evidence that personality traits are related so smartphone use, except for some tentative evidence that neurotic people use more social media and those who generally feel a level of competence in their lives use them less.
<div class="figure"><span id="fig:effects-model1-study1"></span>
<img src="analysis_report_files/figure-html/effects-model1-study1-1.png" alt="Effects plot for Model 1" width="672" />
<p class="caption">
Figure 4.6: Effects plot for Model 1
</p>
</div>
</div>
<div id="model-2-trait-variables-predicting-subjective-use" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Model 2: Trait variables predicting subjective use</h3>
<p>Next up, I predict subjective use from the same predictors.
We know that objective and subjective use aren’t perfectly correlated.
Then again, the priors for Model 1 were only weakly regularizing, which is why I use the same priors again.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="analysis-study-1.html#cb69-1"></a>priors_model2 &lt;-<span class="st"> </span></span>
<span id="cb69-2"><a href="analysis-study-1.html#cb69-2"></a><span class="st">  </span><span class="kw">c</span>(</span>
<span id="cb69-3"><a href="analysis-study-1.html#cb69-3"></a>    <span class="co"># intercept</span></span>
<span id="cb69-4"><a href="analysis-study-1.html#cb69-4"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="fl">4.5</span>, <span class="fl">0.8</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb69-5"><a href="analysis-study-1.html#cb69-5"></a>    </span>
<span id="cb69-6"><a href="analysis-study-1.html#cb69-6"></a>    <span class="co"># prior on effects</span></span>
<span id="cb69-7"><a href="analysis-study-1.html#cb69-7"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.1</span>), <span class="dt">class =</span> b),</span>
<span id="cb69-8"><a href="analysis-study-1.html#cb69-8"></a>    </span>
<span id="cb69-9"><a href="analysis-study-1.html#cb69-9"></a>    <span class="co"># all other effects</span></span>
<span id="cb69-10"><a href="analysis-study-1.html#cb69-10"></a>    <span class="kw">prior</span>(<span class="kw">gamma</span>(<span class="fl">2.5</span>, <span class="dv">100</span>), <span class="dt">class =</span> shape)</span>
<span id="cb69-11"><a href="analysis-study-1.html#cb69-11"></a>  )</span></code></pre></div>
<p>Alright, time to run the model.
The subjective social media estimate had one missing value.
Usually I’d impute missing values during model fitting, but with one, I think it’s safe to drop it.
Again, I add a small constant to the zero values, of which there are 12; not enough, in my opinion, to model zeroes separately.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="analysis-study-1.html#cb70-1"></a>model2 &lt;-<span class="st"> </span></span>
<span id="cb70-2"><a href="analysis-study-1.html#cb70-2"></a><span class="st">  </span><span class="kw">brm</span>(</span>
<span id="cb70-3"><a href="analysis-study-1.html#cb70-3"></a>    <span class="dt">data =</span> study1,</span>
<span id="cb70-4"><a href="analysis-study-1.html#cb70-4"></a>    <span class="dt">family =</span> <span class="kw">Gamma</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>),</span>
<span id="cb70-5"><a href="analysis-study-1.html#cb70-5"></a>    <span class="dt">prior =</span> priors_model2,</span>
<span id="cb70-6"><a href="analysis-study-1.html#cb70-6"></a>    social_media_subjective <span class="op">+</span><span class="st"> </span><span class="fl">1e-6</span> <span class="op">~</span></span>
<span id="cb70-7"><a href="analysis-study-1.html#cb70-7"></a><span class="st">      </span><span class="dv">1</span> <span class="op">+</span></span>
<span id="cb70-8"><a href="analysis-study-1.html#cb70-8"></a><span class="st">      </span>openness_c <span class="op">+</span></span>
<span id="cb70-9"><a href="analysis-study-1.html#cb70-9"></a><span class="st">      </span>conscientiousness_c <span class="op">+</span></span>
<span id="cb70-10"><a href="analysis-study-1.html#cb70-10"></a><span class="st">      </span>extraversion_c <span class="op">+</span></span>
<span id="cb70-11"><a href="analysis-study-1.html#cb70-11"></a><span class="st">      </span>agreeableness_c <span class="op">+</span></span>
<span id="cb70-12"><a href="analysis-study-1.html#cb70-12"></a><span class="st">      </span>neuroticism_c <span class="op">+</span></span>
<span id="cb70-13"><a href="analysis-study-1.html#cb70-13"></a><span class="st">      </span>competence_trait_c <span class="op">+</span></span>
<span id="cb70-14"><a href="analysis-study-1.html#cb70-14"></a><span class="st">      </span>relatedness_trait_c <span class="op">+</span></span>
<span id="cb70-15"><a href="analysis-study-1.html#cb70-15"></a><span class="st">      </span>autonomy_trait_c <span class="op">+</span></span>
<span id="cb70-16"><a href="analysis-study-1.html#cb70-16"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id) <span class="op">+</span></span>
<span id="cb70-17"><a href="analysis-study-1.html#cb70-17"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>day),</span>
<span id="cb70-18"><a href="analysis-study-1.html#cb70-18"></a>    <span class="dt">iter =</span> <span class="dv">5000</span>,</span>
<span id="cb70-19"><a href="analysis-study-1.html#cb70-19"></a>    <span class="dt">warmup =</span> <span class="dv">2000</span>,</span>
<span id="cb70-20"><a href="analysis-study-1.html#cb70-20"></a>    <span class="dt">chains =</span> <span class="dv">4</span>,</span>
<span id="cb70-21"><a href="analysis-study-1.html#cb70-21"></a>    <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb70-22"><a href="analysis-study-1.html#cb70-22"></a>    <span class="dt">seed =</span> <span class="dv">42</span>,</span>
<span id="cb70-23"><a href="analysis-study-1.html#cb70-23"></a>    <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>),</span>
<span id="cb70-24"><a href="analysis-study-1.html#cb70-24"></a>    <span class="dt">file =</span> <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model2_study1&quot;</span>)</span>
<span id="cb70-25"><a href="analysis-study-1.html#cb70-25"></a>  )</span></code></pre></div>
Let’s inspect the traceplots.
Overall, they look fine and the chains seem to have mixed well (Figure <a href="#fig:inspect-model2-study1"><strong>??</strong></a>).
Again, everything looks fine.
<div class="figure"><span id="fig:inspect-model2-study1-1"></span>
<img src="analysis_report_files/figure-html/inspect-model2-study1-1.png" alt="Traceplots and posterior distributions for Model 2" width="672" />
<p class="caption">
Figure 4.7: Traceplots and posterior distributions for Model 2
</p>
</div>
<div class="figure"><span id="fig:inspect-model2-study1-2"></span>
<img src="analysis_report_files/figure-html/inspect-model2-study1-2.png" alt="Traceplots and posterior distributions for Model 2" width="672" />
<p class="caption">
Figure 4.8: Traceplots and posterior distributions for Model 2
</p>
</div>
<div class="figure"><span id="fig:inspect-model2-study1-3"></span>
<img src="analysis_report_files/figure-html/inspect-model2-study1-3.png" alt="Traceplots and posterior distributions for Model 2" width="672" />
<p class="caption">
Figure 4.9: Traceplots and posterior distributions for Model 2
</p>
</div>
The posterior predictive distribution (Figure <a href="#fig:ppc-model2-study2"><strong>??</strong></a>) looks similar to Model 1, with a tendency of the model to underestimate self-reported social media use.
All other diagnostics look similar, which is not surprising given that the outcomes of Model 1 and Model 2 are correlated.
Overall, the model fit is okay-ish, but certainly not excellent.
<div class="figure"><span id="fig:ppc-model2-study1"></span>
<img src="analysis_report_files/figure-html/ppc-model2-study1-1.png" alt="Posterior predictive checks for Model 2" width="672" />
<p class="caption">
Figure 4.10: Posterior predictive checks for Model 2
</p>
</div>
<p>Let’s again check for potentially influential values.
The model diagnostics look good.
Even though there were several rather large raw values on the outcome variable, the model expects them because we model the outcome as a Gamma distribution.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="analysis-study-1.html#cb71-1"></a><span class="kw">loo</span>(model2)</span></code></pre></div>
<p>Alright, time to look at the summary.
This time, all posterior distributions are mostly centered around zero, so we can be 95% (always conditional on the model) certain that personality traits and motivations are not meaningfully (i.e., large effect) related to self-reported social media use.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="analysis-study-1.html#cb72-1"></a><span class="kw">summary</span>(model2, <span class="dt">priors =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>##  Family: gamma 
##   Links: mu = log; shape = identity 
## Formula: social_media_subjective + 1e-06 ~ 1 + openness_c + conscientiousness_c + extraversion_c + agreeableness_c + neuroticism_c + competence_trait_c + relatedness_trait_c + autonomy_trait_c + (1 | id) + (1 | day) 
##    Data: study1 (Number of observations: 430) 
## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Priors: 
## b ~ normal(0, 0.1)
## Intercept ~ normal(4.5, 0.8)
## sd ~ student_t(3, 0, 2.5)
## shape ~ gamma(2.5, 100)
## 
## Group-Level Effects: 
## ~day (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.09      0.10     0.00     0.34 1.00     6500     6025
## 
## ~id (Number of levels: 95) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.21      0.13     0.01     0.48 1.00     2703     5036
## 
## Population-Level Effects: 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept               4.96      0.09     4.78     5.13 1.00     8478     6767
## openness_c             -0.06      0.08    -0.21     0.10 1.00    22685     9320
## conscientiousness_c    -0.05      0.08    -0.21     0.11 1.00    19252     8685
## extraversion_c          0.03      0.07    -0.11     0.17 1.00    17925     9147
## agreeableness_c        -0.03      0.08    -0.18     0.13 1.00    21292     8943
## neuroticism_c           0.04      0.08    -0.12     0.20 1.00    19320     9538
## competence_trait_c     -0.08      0.07    -0.22     0.06 1.00    18448    10289
## relatedness_trait_c    -0.02      0.06    -0.14     0.10 1.00    16023     9253
## autonomy_trait_c       -0.08      0.07    -0.21     0.05 1.00    15905     9666
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## shape     0.62      0.04     0.55     0.70 1.00    11729     8244
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
The effects plot (Figure <a href="analysis-study-1.html#fig:effects-model2-study1">4.11</a>) visually confirms that none of the predictors seem influential.
<div class="figure"><span id="fig:effects-model2-study1"></span>
<img src="analysis_report_files/figure-html/effects-model2-study1-1.png" alt="Effects plot for Model 2" width="672" />
<p class="caption">
Figure 4.11: Effects plot for Model 2
</p>
</div>
</div>
<div id="model-3-trait-variables-predicting-accuracy" class="section level3">
<h3><span class="header-section-number">4.3.3</span> Model 3: Trait variables predicting accuracy</h3>
<p>For this model, it’s hard to choose informed priors, mainly because there’s no literature on the relation between personality traits and accuracy.
Also, it’s unclear what distribution for accuracy we should expect prior to having seen the data.
The few papers out there show that people generally overestimate their (social) media use, which would speak for centering the distribution on a positive value (i.e., positive error).
Other than that, I’d expect a normal distribution, quite likely with fat tails, and possibly right skewed.
Therefore, I’ll use a student-t distribution outcome family.
I start with a t distribution as prior for the intercept that is slightly centered on overestimates (i.e., 20%), but with quite some potential for extreme values and fairly fat tails.
See Figure <a href="analysis-study-1.html#fig:simulate-priors-model2-study1">4.12</a> left panel, for a visualization.</p>
As for the effects of the personality traits, I’ll be skeptical of any effects and thus use weakly regularizing normal priors that are centered on zero, with a small range for the effect: If a person goes from average on a trait to one above average, we’d expect that 95% of the effects should be between -50% and +50% (i.e., SD of 25).
See the right panel in the figure below for a visualization.
<div class="figure"><span id="fig:simulate-priors-model2-study1"></span>
<img src="analysis_report_files/figure-html/simulate-priors-model2-study1-1.png" alt="Prior simmulations for Model 2" width="672" />
<p class="caption">
Figure 4.12: Prior simmulations for Model 2
</p>
</div>
<p>Then let’s set those priors we simulated above.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="analysis-study-1.html#cb74-1"></a>priors_model3 &lt;-<span class="st"> </span></span>
<span id="cb74-2"><a href="analysis-study-1.html#cb74-2"></a><span class="st">  </span><span class="kw">c</span>(</span>
<span id="cb74-3"><a href="analysis-study-1.html#cb74-3"></a>    <span class="co"># intercept</span></span>
<span id="cb74-4"><a href="analysis-study-1.html#cb74-4"></a>    <span class="kw">prior</span>(<span class="kw">student_t</span>(<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb74-5"><a href="analysis-study-1.html#cb74-5"></a>    </span>
<span id="cb74-6"><a href="analysis-study-1.html#cb74-6"></a>    <span class="co"># all other effects</span></span>
<span id="cb74-7"><a href="analysis-study-1.html#cb74-7"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">25</span>), <span class="dt">class =</span> b)</span>
<span id="cb74-8"><a href="analysis-study-1.html#cb74-8"></a>  )</span></code></pre></div>
<p><code>error</code> had 3 missing values.
Again, with such few cases, I’m fine with dropping those during model fitting.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="analysis-study-1.html#cb75-1"></a>model3 &lt;-<span class="st"> </span></span>
<span id="cb75-2"><a href="analysis-study-1.html#cb75-2"></a><span class="st">  </span><span class="kw">brm</span>(</span>
<span id="cb75-3"><a href="analysis-study-1.html#cb75-3"></a>    <span class="dt">data =</span> study1,</span>
<span id="cb75-4"><a href="analysis-study-1.html#cb75-4"></a>    <span class="dt">family =</span> student,</span>
<span id="cb75-5"><a href="analysis-study-1.html#cb75-5"></a>    <span class="dt">prior =</span> priors_model3,</span>
<span id="cb75-6"><a href="analysis-study-1.html#cb75-6"></a>    error <span class="op">~</span></span>
<span id="cb75-7"><a href="analysis-study-1.html#cb75-7"></a><span class="st">      </span><span class="dv">1</span> <span class="op">+</span></span>
<span id="cb75-8"><a href="analysis-study-1.html#cb75-8"></a><span class="st">      </span>openness_c <span class="op">+</span></span>
<span id="cb75-9"><a href="analysis-study-1.html#cb75-9"></a><span class="st">      </span>conscientiousness_c <span class="op">+</span></span>
<span id="cb75-10"><a href="analysis-study-1.html#cb75-10"></a><span class="st">      </span>extraversion_c <span class="op">+</span></span>
<span id="cb75-11"><a href="analysis-study-1.html#cb75-11"></a><span class="st">      </span>agreeableness_c <span class="op">+</span></span>
<span id="cb75-12"><a href="analysis-study-1.html#cb75-12"></a><span class="st">      </span>neuroticism_c <span class="op">+</span></span>
<span id="cb75-13"><a href="analysis-study-1.html#cb75-13"></a><span class="st">      </span>competence_trait_c <span class="op">+</span></span>
<span id="cb75-14"><a href="analysis-study-1.html#cb75-14"></a><span class="st">      </span>relatedness_trait_c <span class="op">+</span></span>
<span id="cb75-15"><a href="analysis-study-1.html#cb75-15"></a><span class="st">      </span>autonomy_trait_c <span class="op">+</span></span>
<span id="cb75-16"><a href="analysis-study-1.html#cb75-16"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id) <span class="op">+</span></span>
<span id="cb75-17"><a href="analysis-study-1.html#cb75-17"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>day),</span>
<span id="cb75-18"><a href="analysis-study-1.html#cb75-18"></a>    <span class="dt">iter =</span> <span class="dv">5000</span>,</span>
<span id="cb75-19"><a href="analysis-study-1.html#cb75-19"></a>    <span class="dt">warmup =</span> <span class="dv">2000</span>,</span>
<span id="cb75-20"><a href="analysis-study-1.html#cb75-20"></a>    <span class="dt">chains =</span> <span class="dv">4</span>,</span>
<span id="cb75-21"><a href="analysis-study-1.html#cb75-21"></a>    <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb75-22"><a href="analysis-study-1.html#cb75-22"></a>    <span class="dt">seed =</span> <span class="dv">42</span>,</span>
<span id="cb75-23"><a href="analysis-study-1.html#cb75-23"></a>    <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>),</span>
<span id="cb75-24"><a href="analysis-study-1.html#cb75-24"></a>    <span class="dt">file =</span> <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model3_study1&quot;</span>)</span>
<span id="cb75-25"><a href="analysis-study-1.html#cb75-25"></a>  )</span></code></pre></div>
Overall, the traceplots look fine and the chains seem to have mixed well, see (Figure <a href="#fig:inspect-model3-study1"><strong>??</strong></a>).
Again, the variance around the residuals for the day grouping is estimated to be small and zero often.
<div class="figure"><span id="fig:inspect-model3-study1-1"></span>
<img src="analysis_report_files/figure-html/inspect-model3-study1-1.png" alt="Traceplots and posterior distributions for Model 3" width="672" />
<p class="caption">
Figure 4.13: Traceplots and posterior distributions for Model 3
</p>
</div>
<div class="figure"><span id="fig:inspect-model3-study1-2"></span>
<img src="analysis_report_files/figure-html/inspect-model3-study1-2.png" alt="Traceplots and posterior distributions for Model 3" width="672" />
<p class="caption">
Figure 4.14: Traceplots and posterior distributions for Model 3
</p>
</div>
<div class="figure"><span id="fig:inspect-model3-study1-3"></span>
<img src="analysis_report_files/figure-html/inspect-model3-study1-3.png" alt="Traceplots and posterior distributions for Model 3" width="672" />
<p class="caption">
Figure 4.15: Traceplots and posterior distributions for Model 3
</p>
</div>
The posterior predictive checks (Figure <a href="#fig:ppc-model3-study1"><strong>??</strong></a>) look good.
Note that the upper left panel looks strange because of the massive scale on the x-axis, which is why I reproduce it again at the bottom.
We see that the student t distribution assigns too much posterior mass to negative values, whereas the data are right skewed.
For even better fit, we might think about fitting a skew-normal outcome distribution, but I’d say that the student-t was most appropriate before seeing the data.
We see that the current models does an okay job in recovering the mean and the median.
<div class="figure"><span id="fig:ppc-model3-study1-1"></span>
<img src="analysis_report_files/figure-html/ppc-model3-study1-1.png" alt="Posterior predictive checks for Model 3" width="672" />
<p class="caption">
Figure 4.16: Posterior predictive checks for Model 3
</p>
</div>
<div class="figure"><span id="fig:ppc-model3-study1-2"></span>
<img src="analysis_report_files/figure-html/ppc-model3-study1-2.png" alt="Posterior predictive checks for Model 3" width="672" />
<p class="caption">
Figure 4.17: Posterior predictive checks for Model 3
</p>
</div>
<p>Let’s again check for potentially influential values.
Three potentially influential cases are flagged, which is why we calculate them precisely by setting <code>reloo</code> to <code>TRUE</code>.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="analysis-study-1.html#cb76-1"></a>model3_loo &lt;-<span class="st"> </span><span class="kw">loo</span>(model3, <span class="dt">reloo =</span> <span class="ot">TRUE</span>)</span>
<span id="cb76-2"><a href="analysis-study-1.html#cb76-2"></a><span class="kw">saveRDS</span>(model3_loo, <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model3_loo_study1.rds&quot;</span>))</span></code></pre></div>
<p>When we calculate ELPD directly, all values appear unproblematic.
The results seem trustworthy.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="analysis-study-1.html#cb77-1"></a>model3_loo &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model3_loo_study1.rds&quot;</span>))</span>
<span id="cb77-2"><a href="analysis-study-1.html#cb77-2"></a>model3_loo</span></code></pre></div>
<pre><code>## 
## Computed from 12000 by 428 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -2407.7 31.0
## p_loo       141.9  7.1
## looic      4815.4 62.0
## ------
## Monte Carlo SE of elpd_loo is 0.2.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     422   98.6%   144       
##  (0.5, 0.7]   (ok)         6    1.4%   2503      
##    (0.7, 1]   (bad)        0    0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>Let’s inspect the summary.
There doesn’t seem to be much going on when it comes to the predictors.
For all predictors, we cannot be 95% certain that zero isn’t the true effect (conditional on the model).</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="analysis-study-1.html#cb79-1"></a><span class="kw">summary</span>(model3, <span class="dt">priors =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>##  Family: student 
##   Links: mu = identity; sigma = identity; nu = identity 
## Formula: error ~ 1 + openness_c + conscientiousness_c + extraversion_c + agreeableness_c + neuroticism_c + competence_trait_c + relatedness_trait_c + autonomy_trait_c + (1 | id) + (1 | day) 
##    Data: study1 (Number of observations: 428) 
## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Priors: 
## b ~ normal(0, 25)
## Intercept ~ student_t(10, 20, 100)
## nu ~ gamma(2, 0.1)
## sd ~ student_t(3, 0, 57.9)
## sigma ~ student_t(3, 0, 57.9)
## 
## Group-Level Effects: 
## ~day (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     3.29      3.43     0.11    11.83 1.00     4989     5340
## 
## ~id (Number of levels: 95) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    64.75      6.12    53.80    77.57 1.00     2095     4185
## 
## Population-Level Effects: 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept               9.65      7.74    -5.42    24.93 1.00     2074     3521
## openness_c            -18.33     13.16   -44.08     7.38 1.00     2776     5107
## conscientiousness_c    -2.94     12.90   -28.51    22.68 1.00     2732     4193
## extraversion_c         -6.71      9.44   -25.27    11.51 1.00     2108     4210
## agreeableness_c        -6.27     12.82   -31.86    18.62 1.00     2406     4265
## neuroticism_c         -21.50     13.74   -48.31     5.70 1.00     2794     4522
## competence_trait_c      6.24     10.86   -15.36    27.03 1.00     2580     3557
## relatedness_trait_c    -0.64      8.96   -18.15    16.70 1.00     2359     4329
## autonomy_trait_c       -3.67      9.47   -22.17    14.82 1.00     2920     4850
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    22.34      2.22    18.33    26.85 1.00     4881     7747
## nu        1.21      0.12     1.02     1.48 1.00     5088     4131
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
The effects plot (Figure <a href="analysis-study-1.html#fig:effects-model3-study1">4.18</a>) visually confirms that none of the predictors seem largely influential.
If anything, it appears neurotic people might underestimate their social media use, but again their interval contains zero.
<div class="figure"><span id="fig:effects-model3-study1"></span>
<img src="analysis_report_files/figure-html/effects-model3-study1-1.png" alt="Effects plot for Model 3" width="672" />
<p class="caption">
Figure 4.18: Effects plot for Model 3
</p>
</div>
</div>
</div>
<div id="do-state-i.e.-day-level-variables-predict-social-media-use-and-accuracy" class="section level2">
<h2><span class="header-section-number">4.4</span> Do state (i.e., day-level) variables predict social media use and accuracy?</h2>
<p>For the next section, we look at whether day-level variables (i.e., variables reported during experience sampling) predict subjective use, objective use, and accuracy.
Again, we have three questions:</p>
<ol style="list-style-type: decimal">
<li>Do day-level variables predict objective-only engagement?</li>
<li>Do day-level variables predict subjective-only engagement?</li>
<li>Do day-level variables predict accuracy?</li>
</ol>
<p>Once more I’ll construct a model for each of those three questions.
Our dependent variables are the same as in the previous block of models: <code>social_media_objective</code>, <code>social_media_subjective</code>, and <code>error</code>.</p>
<p>Our predictors will be variables on the day-level, so state variables: need satisfaction for autonomy, competence, and relatedness as well as four experiential qualities during participants’ days (boredom, enjoyment, satisfaction, and stress).</p>
<p>Because we want to separate between-person and within-person effects, we’ll do group-mean centering (i.e., per participant) and the calculate the deviation of each observation from that group mean.
We enter both the person mean and their deviation as predictors, which will lead to a lot of variables, because each of the seven predictors will be separated into a between-person and a within-person predictor.
See <a href="https://philippmasur.de/2018/05/23/how-to-center-in-multilevel-models/">this</a> blogpost for a tutorial on centering.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="analysis-study-1.html#cb81-1"></a>study1 &lt;-<span class="st"> </span></span>
<span id="cb81-2"><a href="analysis-study-1.html#cb81-2"></a><span class="st">  </span>study1 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb81-3"><a href="analysis-study-1.html#cb81-3"></a><span class="st">  </span><span class="kw">group_by</span>(id) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb81-4"><a href="analysis-study-1.html#cb81-4"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb81-5"><a href="analysis-study-1.html#cb81-5"></a>    <span class="kw">across</span>(</span>
<span id="cb81-6"><a href="analysis-study-1.html#cb81-6"></a>      <span class="kw">c</span>(autonomy_state<span class="op">:</span>relatedness_state, satisfied<span class="op">:</span>enjoyable),</span>
<span id="cb81-7"><a href="analysis-study-1.html#cb81-7"></a>      <span class="kw">list</span>(</span>
<span id="cb81-8"><a href="analysis-study-1.html#cb81-8"></a>        <span class="dt">between =</span> <span class="op">~</span><span class="st"> </span><span class="kw">mean</span>(.x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),</span>
<span id="cb81-9"><a href="analysis-study-1.html#cb81-9"></a>        <span class="dt">within =</span> <span class="op">~</span>.x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(.x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</span>
<span id="cb81-10"><a href="analysis-study-1.html#cb81-10"></a>      )</span>
<span id="cb81-11"><a href="analysis-study-1.html#cb81-11"></a>    )</span>
<span id="cb81-12"><a href="analysis-study-1.html#cb81-12"></a>  ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb81-13"><a href="analysis-study-1.html#cb81-13"></a><span class="st">  </span><span class="kw">ungroup</span>()</span></code></pre></div>
<div id="model-4-state-variables-predicting-objective-use" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Model 4: State variables predicting objective use</h3>
<p>First, I choose sensible priors.
In contrast to previous models, there isn’t much literature that could inform priors on our predictors.
The same goes for the experiential qualities.
We’ll go with a “maximal” model where each participant and day get their own intercept plus random slopes nested within participant, because it’s plausible that the effects vary per participant.
They could also vary by day, but a) there was little to no variation for day in previous models, and b) that would lead to more parameters than our little data could handle.
Just like before we assume a Gamma distribution for the social media variables.</p>
<p>I’ll go step-by-step:</p>
<ul>
<li>For the intercepts, I use the same prior as above in Models 1 and 2.</li>
<li>For basic psychological needs fixed effects, <a href="https://www.tandfonline.com/doi/abs/10.1080/15309576.2017.1400991">this</a> paper reports very small relations between self-determined motivations at work and social media use (<span class="math inline">\(\beta\)</span> &lt; .06).
However, most of the literature focuses on those motivations and social media addiction, enjoyment of social media, or satisfaction with social media.
Therefore, I’ll use weakly regularizing priors for those effects, which means I’ll go with the same prior for the effects as for Models 1 and 2.
I would expect larger differences on the between-level, based on the literature on media use and well-being.
However, we don’t have that info for our predictors and the priors are rather weak, so I’ll apply them to both between and within predictors.</li>
<li>For the experiential qualities, there isn’t much literature out there that would allow choosing an informed prior.
Most of those experiential qualities are about having a fulfilled and good day, which taps into the whole controversy over the relation between such experiences and social media.
Therefore, I’ll take a skeptical stance here and again assign the same weakly regularizing priors (aka the priors we also used for Models 1 and 2).</li>
<li>For the variances (sigmas) I’ll take the <code>brms</code> default priors because I have no prior information, nor how the effects vary across day and participant.</li>
<li>For the correlation between intercepts and slopes, I’ll again use the default prior, mostly because those have shown to help with convergence and I don’t have good information on which correlation to expect.</li>
</ul>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="analysis-study-1.html#cb82-1"></a>priors_model4 &lt;-<span class="st"> </span></span>
<span id="cb82-2"><a href="analysis-study-1.html#cb82-2"></a><span class="st">  </span><span class="kw">c</span>(</span>
<span id="cb82-3"><a href="analysis-study-1.html#cb82-3"></a>    <span class="co"># intercept</span></span>
<span id="cb82-4"><a href="analysis-study-1.html#cb82-4"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="fl">4.5</span>, <span class="fl">0.8</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb82-5"><a href="analysis-study-1.html#cb82-5"></a>    </span>
<span id="cb82-6"><a href="analysis-study-1.html#cb82-6"></a>    <span class="co"># prior on effects</span></span>
<span id="cb82-7"><a href="analysis-study-1.html#cb82-7"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.1</span>), <span class="dt">class =</span> b),</span>
<span id="cb82-8"><a href="analysis-study-1.html#cb82-8"></a>    </span>
<span id="cb82-9"><a href="analysis-study-1.html#cb82-9"></a>    <span class="co"># prior on shape</span></span>
<span id="cb82-10"><a href="analysis-study-1.html#cb82-10"></a>    <span class="kw">prior</span>(<span class="kw">gamma</span>(<span class="fl">2.5</span>, <span class="dv">100</span>), <span class="dt">class =</span> shape)</span>
<span id="cb82-11"><a href="analysis-study-1.html#cb82-11"></a>  )</span></code></pre></div>
<p>Let’s run the model.
Note that the within-deviations can vary per participant, but not the between effects.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="analysis-study-1.html#cb83-1"></a>model4 &lt;-<span class="st"> </span></span>
<span id="cb83-2"><a href="analysis-study-1.html#cb83-2"></a><span class="st">  </span><span class="kw">brm</span>(</span>
<span id="cb83-3"><a href="analysis-study-1.html#cb83-3"></a>    <span class="dt">data =</span> study1,</span>
<span id="cb83-4"><a href="analysis-study-1.html#cb83-4"></a>    <span class="dt">family =</span> <span class="kw">Gamma</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>),</span>
<span id="cb83-5"><a href="analysis-study-1.html#cb83-5"></a>    <span class="dt">prior =</span> priors_model4,</span>
<span id="cb83-6"><a href="analysis-study-1.html#cb83-6"></a>    social_media_objective <span class="op">+</span><span class="st"> </span><span class="fl">1e-6</span> <span class="op">~</span></span>
<span id="cb83-7"><a href="analysis-study-1.html#cb83-7"></a><span class="st">      </span><span class="dv">1</span> <span class="op">+</span></span>
<span id="cb83-8"><a href="analysis-study-1.html#cb83-8"></a><span class="st">      </span>autonomy_state_between <span class="op">+</span></span>
<span id="cb83-9"><a href="analysis-study-1.html#cb83-9"></a><span class="st">      </span>competence_state_between <span class="op">+</span></span>
<span id="cb83-10"><a href="analysis-study-1.html#cb83-10"></a><span class="st">      </span>relatedness_state_between <span class="op">+</span></span>
<span id="cb83-11"><a href="analysis-study-1.html#cb83-11"></a><span class="st">      </span>satisfied_between <span class="op">+</span></span>
<span id="cb83-12"><a href="analysis-study-1.html#cb83-12"></a><span class="st">      </span>boring_between <span class="op">+</span></span>
<span id="cb83-13"><a href="analysis-study-1.html#cb83-13"></a><span class="st">      </span>stressful_between <span class="op">+</span></span>
<span id="cb83-14"><a href="analysis-study-1.html#cb83-14"></a><span class="st">      </span>enjoyable_between <span class="op">+</span></span>
<span id="cb83-15"><a href="analysis-study-1.html#cb83-15"></a><span class="st">      </span>autonomy_state_within <span class="op">+</span></span>
<span id="cb83-16"><a href="analysis-study-1.html#cb83-16"></a><span class="st">      </span>competence_state_within <span class="op">+</span></span>
<span id="cb83-17"><a href="analysis-study-1.html#cb83-17"></a><span class="st">      </span>relatedness_state_within <span class="op">+</span></span>
<span id="cb83-18"><a href="analysis-study-1.html#cb83-18"></a><span class="st">      </span>satisfied_within <span class="op">+</span></span>
<span id="cb83-19"><a href="analysis-study-1.html#cb83-19"></a><span class="st">      </span>boring_within <span class="op">+</span></span>
<span id="cb83-20"><a href="analysis-study-1.html#cb83-20"></a><span class="st">      </span>stressful_within <span class="op">+</span></span>
<span id="cb83-21"><a href="analysis-study-1.html#cb83-21"></a><span class="st">      </span>enjoyable_within <span class="op">+</span></span>
<span id="cb83-22"><a href="analysis-study-1.html#cb83-22"></a><span class="st">      </span>(</span>
<span id="cb83-23"><a href="analysis-study-1.html#cb83-23"></a>        <span class="dv">1</span> <span class="op">+</span></span>
<span id="cb83-24"><a href="analysis-study-1.html#cb83-24"></a><span class="st">        </span>autonomy_state_within <span class="op">+</span></span>
<span id="cb83-25"><a href="analysis-study-1.html#cb83-25"></a><span class="st">        </span>competence_state_within <span class="op">+</span></span>
<span id="cb83-26"><a href="analysis-study-1.html#cb83-26"></a><span class="st">        </span>relatedness_state_within <span class="op">+</span></span>
<span id="cb83-27"><a href="analysis-study-1.html#cb83-27"></a><span class="st">        </span>satisfied_within <span class="op">+</span></span>
<span id="cb83-28"><a href="analysis-study-1.html#cb83-28"></a><span class="st">        </span>boring_within <span class="op">+</span></span>
<span id="cb83-29"><a href="analysis-study-1.html#cb83-29"></a><span class="st">        </span>stressful_within <span class="op">+</span></span>
<span id="cb83-30"><a href="analysis-study-1.html#cb83-30"></a><span class="st">        </span>enjoyable_within <span class="op">|</span></span>
<span id="cb83-31"><a href="analysis-study-1.html#cb83-31"></a><span class="st">        </span>id</span>
<span id="cb83-32"><a href="analysis-study-1.html#cb83-32"></a>      ) <span class="op">+</span></span>
<span id="cb83-33"><a href="analysis-study-1.html#cb83-33"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span>day),</span>
<span id="cb83-34"><a href="analysis-study-1.html#cb83-34"></a>    <span class="dt">iter =</span> <span class="dv">5000</span>,</span>
<span id="cb83-35"><a href="analysis-study-1.html#cb83-35"></a>    <span class="dt">warmup =</span> <span class="dv">2000</span>,</span>
<span id="cb83-36"><a href="analysis-study-1.html#cb83-36"></a>    <span class="dt">chains =</span> <span class="dv">4</span>,</span>
<span id="cb83-37"><a href="analysis-study-1.html#cb83-37"></a>    <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb83-38"><a href="analysis-study-1.html#cb83-38"></a>    <span class="dt">seed =</span> <span class="dv">42</span>,</span>
<span id="cb83-39"><a href="analysis-study-1.html#cb83-39"></a>    <span class="dt">control =</span> <span class="kw">list</span>(</span>
<span id="cb83-40"><a href="analysis-study-1.html#cb83-40"></a>      <span class="dt">adapt_delta =</span> <span class="fl">0.99</span></span>
<span id="cb83-41"><a href="analysis-study-1.html#cb83-41"></a>    ),</span>
<span id="cb83-42"><a href="analysis-study-1.html#cb83-42"></a>    <span class="dt">file =</span> <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model4_study1&quot;</span>)</span>
<span id="cb83-43"><a href="analysis-study-1.html#cb83-43"></a>  )</span></code></pre></div>
Overall, the traceplots look fine and the chains seem to have mixed well (Figure <a href="#fig:inspect-model5-study1"><strong>??</strong></a>).
Again the variance around the day grouping is small and mostly estimated to be zero or close to zero.
<div class="figure"><span id="fig:inspect-model4-study1-1"></span>
<img src="analysis_report_files/figure-html/inspect-model4-study1-1.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.19: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model4-study1-2"></span>
<img src="analysis_report_files/figure-html/inspect-model4-study1-2.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.20: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model4-study1-3"></span>
<img src="analysis_report_files/figure-html/inspect-model4-study1-3.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.21: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model4-study1-4"></span>
<img src="analysis_report_files/figure-html/inspect-model4-study1-4.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.22: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model4-study1-5"></span>
<img src="analysis_report_files/figure-html/inspect-model4-study1-5.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.23: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model4-study1-6"></span>
<img src="analysis_report_files/figure-html/inspect-model4-study1-6.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.24: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model4-study1-7"></span>
<img src="analysis_report_files/figure-html/inspect-model4-study1-7.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.25: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model4-study1-8"></span>
<img src="analysis_report_files/figure-html/inspect-model4-study1-8.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.26: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model4-study1-9"></span>
<img src="analysis_report_files/figure-html/inspect-model4-study1-9.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.27: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model4-study1-10"></span>
<img src="analysis_report_files/figure-html/inspect-model4-study1-10.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.28: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model4-study1-11"></span>
<img src="analysis_report_files/figure-html/inspect-model4-study1-11.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.29: Traceplots and posterior distributions for Model 4
</p>
</div>
The posterior predictive check shows that the model does a mediocre job.
The model does a good job retrieving the mean, but underestimates social media use once more.
Also, the LOO-PIT diagnostics look like a different distribution will fit better, potentially a skewed normal or beta-distribution.
<div class="figure"><span id="fig:ppc-model4-study1"></span>
<img src="analysis_report_files/figure-html/ppc-model4-study1-1.png" alt="Posterior predictive checks for Model 4" width="672" />
<p class="caption">
Figure 4.30: Posterior predictive checks for Model 4
</p>
</div>
<p>Next, we check for potentially influential cases.
There are none.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="analysis-study-1.html#cb84-1"></a><span class="kw">loo</span>(model4, <span class="dt">reloo =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## No problematic observations found. Returning the original &#39;loo&#39; object.</code></pre>
<pre><code>## 
## Computed from 12000 by 427 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -2464.8 15.0
## p_loo        26.5  2.6
## looic      4929.7 30.0
## ------
## Monte Carlo SE of elpd_loo is 0.1.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     415   97.2%   1124      
##  (0.5, 0.7]   (ok)        12    2.8%   4162      
##    (0.7, 1]   (bad)        0    0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>Let’s inspect the summary.
There doesn’t seem to be much going on when it comes to the predictors.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="analysis-study-1.html#cb87-1"></a><span class="kw">summary</span>(model4, <span class="dt">priors =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>##  Family: gamma 
##   Links: mu = log; shape = identity 
## Formula: social_media_objective + 1e-06 ~ 1 + autonomy_state_between + competence_state_between + relatedness_state_between + satisfied_between + boring_between + stressful_between + enjoyable_between + autonomy_state_within + competence_state_within + relatedness_state_within + satisfied_within + boring_within + stressful_within + enjoyable_within + (1 + autonomy_state_within + competence_state_within + relatedness_state_within + satisfied_within + boring_within + stressful_within + enjoyable_within | id) + (1 | day) 
##    Data: study1 (Number of observations: 427) 
## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Priors: 
## b ~ normal(0, 0.1)
## Intercept ~ normal(4.5, 0.8)
## L ~ lkj_corr_cholesky(1)
## sd ~ student_t(3, 0, 2.5)
## shape ~ gamma(2.5, 100)
## 
## Group-Level Effects: 
## ~day (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.07      0.08     0.00     0.28 1.00     5573     6121
## 
## ~id (Number of levels: 95) 
##                                                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)                                             0.52      0.08     0.38     0.68 1.00     3731     5419
## sd(autonomy_state_within)                                 0.06      0.04     0.00     0.16 1.00     9093     5765
## sd(competence_state_within)                               0.05      0.04     0.00     0.15 1.00     9601     6891
## sd(relatedness_state_within)                              0.07      0.05     0.00     0.19 1.00     9121     5484
## sd(satisfied_within)                                      0.04      0.03     0.00     0.12 1.00     9055     5687
## sd(boring_within)                                         0.04      0.03     0.00     0.10 1.00     8522     5456
## sd(stressful_within)                                      0.03      0.02     0.00     0.09 1.00     9657     6464
## sd(enjoyable_within)                                      0.04      0.03     0.00     0.12 1.00     8883     5303
## cor(Intercept,autonomy_state_within)                     -0.03      0.33    -0.66     0.61 1.00    16752     7831
## cor(Intercept,competence_state_within)                   -0.04      0.33    -0.65     0.60 1.00    20798     8116
## cor(autonomy_state_within,competence_state_within)       -0.04      0.33    -0.67     0.60 1.00    15010     9162
## cor(Intercept,relatedness_state_within)                   0.01      0.32    -0.61     0.62 1.00    18875     8132
## cor(autonomy_state_within,relatedness_state_within)      -0.02      0.34    -0.65     0.61 1.00    16262     9402
## cor(competence_state_within,relatedness_state_within)    -0.02      0.33    -0.65     0.61 1.00    11183     9930
## cor(Intercept,satisfied_within)                          -0.02      0.33    -0.64     0.62 1.00    18288     9222
## cor(autonomy_state_within,satisfied_within)              -0.03      0.33    -0.65     0.61 1.00    14336     8847
## cor(competence_state_within,satisfied_within)            -0.04      0.34    -0.66     0.61 1.00    11307     9545
## cor(relatedness_state_within,satisfied_within)           -0.02      0.34    -0.66     0.62 1.00    10340     9602
## cor(Intercept,boring_within)                              0.05      0.33    -0.60     0.67 1.00    20721     8906
## cor(autonomy_state_within,boring_within)                  0.03      0.34    -0.61     0.66 1.00    14453     7294
## cor(competence_state_within,boring_within)                0.02      0.34    -0.62     0.65 1.00    11792     9296
## cor(relatedness_state_within,boring_within)               0.01      0.33    -0.63     0.64 1.00    10308     8907
## cor(satisfied_within,boring_within)                       0.02      0.33    -0.61     0.64 1.00     8821     9160
## cor(Intercept,stressful_within)                           0.01      0.33    -0.62     0.63 1.00    17870     7579
## cor(autonomy_state_within,stressful_within)               0.04      0.34    -0.63     0.67 1.00    14481     8934
## cor(competence_state_within,stressful_within)             0.02      0.34    -0.63     0.66 1.00    13201     8995
## cor(relatedness_state_within,stressful_within)            0.01      0.34    -0.63     0.63 1.00    10632     9642
## cor(satisfied_within,stressful_within)                    0.02      0.33    -0.60     0.64 1.00     9347     9626
## cor(boring_within,stressful_within)                      -0.02      0.33    -0.64     0.62 1.00     7624     9174
## cor(Intercept,enjoyable_within)                          -0.05      0.34    -0.68     0.61 1.00    16767     8057
## cor(autonomy_state_within,enjoyable_within)              -0.03      0.34    -0.67     0.63 1.00    13968     8479
## cor(competence_state_within,enjoyable_within)            -0.04      0.34    -0.65     0.62 1.00    10919     9017
## cor(relatedness_state_within,enjoyable_within)           -0.02      0.33    -0.64     0.62 1.00    10434     8994
## cor(satisfied_within,enjoyable_within)                   -0.04      0.33    -0.66     0.61 1.00     8698     9966
## cor(boring_within,enjoyable_within)                       0.02      0.34    -0.63     0.65 1.00     7365     9237
## cor(stressful_within,enjoyable_within)                    0.02      0.33    -0.61     0.64 1.00     6760     8993
## 
## Population-Level Effects: 
##                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept                     4.48      0.65     3.18     5.76 1.00     8674     9019
## autonomy_state_between       -0.03      0.08    -0.18     0.11 1.00     9500     8756
## competence_state_between      0.03      0.07    -0.11     0.17 1.00     9513     8809
## relatedness_state_between    -0.01      0.07    -0.15     0.13 1.00    10154     9788
## satisfied_between            -0.03      0.07    -0.17     0.12 1.00    10968     9514
## boring_between                0.04      0.06    -0.07     0.15 1.00     8893     8810
## stressful_between             0.01      0.05    -0.09     0.12 1.00     8132     8654
## enjoyable_between             0.08      0.08    -0.07     0.23 1.00     9821     8833
## autonomy_state_within        -0.00      0.06    -0.12     0.11 1.00    17097     9669
## competence_state_within      -0.05      0.06    -0.16     0.06 1.00    15473     9608
## relatedness_state_within      0.01      0.06    -0.12     0.13 1.00    20322     8631
## satisfied_within              0.01      0.05    -0.09     0.11 1.00    16513     8687
## boring_within                -0.01      0.04    -0.09     0.07 1.00    17110     8944
## stressful_within             -0.02      0.04    -0.09     0.05 1.00    16532     9132
## enjoyable_within              0.03      0.05    -0.06     0.13 1.00    16225     8880
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## shape     1.29      0.09     1.12     1.48 1.00     9168     8692
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
The effects plot (Figure <a href="analysis-study-1.html#fig:effects-model4-study1">4.31</a>) visually confirms that none of the predictors seem influential.
Note that the correlations between random effects are on different scales which explains why the CI around them are so wide.
Except for the correlations, all effects are on the log scale because we used a Gamma distribution, but the correlations are regularly on a scale of -1 to 1.
<div class="figure"><span id="fig:effects-model4-study1"></span>
<img src="analysis_report_files/figure-html/effects-model4-study1-1.png" alt="Effects plot for Model 4" width="672" />
<p class="caption">
Figure 4.31: Effects plot for Model 4
</p>
</div>
</div>
<div id="model-5-state-variables-predicting-subjective-use" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Model 5: State variables predicting subjective use</h3>
<p>The next model predicts subjective use from the same predictors.
Once more, we know that subjective and objective use aren’t perfectly correlated, but the priors for Model 4 again are our best bet here (for both within-person and between-person effects).</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="analysis-study-1.html#cb89-1"></a>priors_model5 &lt;-<span class="st"> </span></span>
<span id="cb89-2"><a href="analysis-study-1.html#cb89-2"></a><span class="st">  </span><span class="kw">c</span>(</span>
<span id="cb89-3"><a href="analysis-study-1.html#cb89-3"></a>    <span class="co"># intercept</span></span>
<span id="cb89-4"><a href="analysis-study-1.html#cb89-4"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="fl">4.5</span>, <span class="fl">0.8</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb89-5"><a href="analysis-study-1.html#cb89-5"></a>    </span>
<span id="cb89-6"><a href="analysis-study-1.html#cb89-6"></a>    <span class="co"># prior on effects</span></span>
<span id="cb89-7"><a href="analysis-study-1.html#cb89-7"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.1</span>), <span class="dt">class =</span> b),</span>
<span id="cb89-8"><a href="analysis-study-1.html#cb89-8"></a>    </span>
<span id="cb89-9"><a href="analysis-study-1.html#cb89-9"></a>    <span class="co"># prior on shape</span></span>
<span id="cb89-10"><a href="analysis-study-1.html#cb89-10"></a>    <span class="kw">prior</span>(<span class="kw">gamma</span>(<span class="fl">2.5</span>, <span class="dv">100</span>), <span class="dt">class =</span> shape)</span>
<span id="cb89-11"><a href="analysis-study-1.html#cb89-11"></a>  )</span></code></pre></div>
<p>Let’s run the model.
Like with Model 2, we don’t separately model zeros.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="analysis-study-1.html#cb90-1"></a>model5 &lt;-<span class="st"> </span></span>
<span id="cb90-2"><a href="analysis-study-1.html#cb90-2"></a><span class="st">  </span><span class="kw">brm</span>(</span>
<span id="cb90-3"><a href="analysis-study-1.html#cb90-3"></a>    <span class="dt">data =</span> study1,</span>
<span id="cb90-4"><a href="analysis-study-1.html#cb90-4"></a>    <span class="dt">family =</span> <span class="kw">Gamma</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>),</span>
<span id="cb90-5"><a href="analysis-study-1.html#cb90-5"></a>    <span class="dt">prior =</span> priors_model4,</span>
<span id="cb90-6"><a href="analysis-study-1.html#cb90-6"></a>    social_media_subjective <span class="op">+</span><span class="st"> </span><span class="fl">1e-6</span> <span class="op">~</span></span>
<span id="cb90-7"><a href="analysis-study-1.html#cb90-7"></a><span class="st">      </span><span class="dv">1</span> <span class="op">+</span></span>
<span id="cb90-8"><a href="analysis-study-1.html#cb90-8"></a><span class="st">      </span>autonomy_state_between <span class="op">+</span></span>
<span id="cb90-9"><a href="analysis-study-1.html#cb90-9"></a><span class="st">      </span>competence_state_between <span class="op">+</span></span>
<span id="cb90-10"><a href="analysis-study-1.html#cb90-10"></a><span class="st">      </span>relatedness_state_between <span class="op">+</span></span>
<span id="cb90-11"><a href="analysis-study-1.html#cb90-11"></a><span class="st">      </span>satisfied_between <span class="op">+</span></span>
<span id="cb90-12"><a href="analysis-study-1.html#cb90-12"></a><span class="st">      </span>boring_between <span class="op">+</span></span>
<span id="cb90-13"><a href="analysis-study-1.html#cb90-13"></a><span class="st">      </span>stressful_between <span class="op">+</span></span>
<span id="cb90-14"><a href="analysis-study-1.html#cb90-14"></a><span class="st">      </span>enjoyable_between <span class="op">+</span></span>
<span id="cb90-15"><a href="analysis-study-1.html#cb90-15"></a><span class="st">      </span>autonomy_state_within <span class="op">+</span></span>
<span id="cb90-16"><a href="analysis-study-1.html#cb90-16"></a><span class="st">      </span>competence_state_within <span class="op">+</span></span>
<span id="cb90-17"><a href="analysis-study-1.html#cb90-17"></a><span class="st">      </span>relatedness_state_within <span class="op">+</span></span>
<span id="cb90-18"><a href="analysis-study-1.html#cb90-18"></a><span class="st">      </span>satisfied_within <span class="op">+</span></span>
<span id="cb90-19"><a href="analysis-study-1.html#cb90-19"></a><span class="st">      </span>boring_within <span class="op">+</span></span>
<span id="cb90-20"><a href="analysis-study-1.html#cb90-20"></a><span class="st">      </span>stressful_within <span class="op">+</span></span>
<span id="cb90-21"><a href="analysis-study-1.html#cb90-21"></a><span class="st">      </span>enjoyable_within <span class="op">+</span></span>
<span id="cb90-22"><a href="analysis-study-1.html#cb90-22"></a><span class="st">      </span>(</span>
<span id="cb90-23"><a href="analysis-study-1.html#cb90-23"></a>        <span class="dv">1</span> <span class="op">+</span></span>
<span id="cb90-24"><a href="analysis-study-1.html#cb90-24"></a><span class="st">        </span>autonomy_state_within <span class="op">+</span></span>
<span id="cb90-25"><a href="analysis-study-1.html#cb90-25"></a><span class="st">        </span>competence_state_within <span class="op">+</span></span>
<span id="cb90-26"><a href="analysis-study-1.html#cb90-26"></a><span class="st">        </span>relatedness_state_within <span class="op">+</span></span>
<span id="cb90-27"><a href="analysis-study-1.html#cb90-27"></a><span class="st">        </span>satisfied_within <span class="op">+</span></span>
<span id="cb90-28"><a href="analysis-study-1.html#cb90-28"></a><span class="st">        </span>boring_within <span class="op">+</span></span>
<span id="cb90-29"><a href="analysis-study-1.html#cb90-29"></a><span class="st">        </span>stressful_within <span class="op">+</span></span>
<span id="cb90-30"><a href="analysis-study-1.html#cb90-30"></a><span class="st">        </span>enjoyable_within <span class="op">|</span></span>
<span id="cb90-31"><a href="analysis-study-1.html#cb90-31"></a><span class="st">        </span>id</span>
<span id="cb90-32"><a href="analysis-study-1.html#cb90-32"></a>      ) <span class="op">+</span></span>
<span id="cb90-33"><a href="analysis-study-1.html#cb90-33"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span>day),</span>
<span id="cb90-34"><a href="analysis-study-1.html#cb90-34"></a>    <span class="dt">iter =</span> <span class="dv">5000</span>,</span>
<span id="cb90-35"><a href="analysis-study-1.html#cb90-35"></a>    <span class="dt">warmup =</span> <span class="dv">2000</span>,</span>
<span id="cb90-36"><a href="analysis-study-1.html#cb90-36"></a>    <span class="dt">chains =</span> <span class="dv">4</span>,</span>
<span id="cb90-37"><a href="analysis-study-1.html#cb90-37"></a>    <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb90-38"><a href="analysis-study-1.html#cb90-38"></a>    <span class="dt">seed =</span> <span class="dv">42</span>,</span>
<span id="cb90-39"><a href="analysis-study-1.html#cb90-39"></a>    <span class="dt">control =</span> <span class="kw">list</span>(</span>
<span id="cb90-40"><a href="analysis-study-1.html#cb90-40"></a>      <span class="dt">adapt_delta =</span> <span class="fl">0.99</span></span>
<span id="cb90-41"><a href="analysis-study-1.html#cb90-41"></a>    ),</span>
<span id="cb90-42"><a href="analysis-study-1.html#cb90-42"></a>    <span class="dt">file =</span> <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model5_study1&quot;</span>)</span>
<span id="cb90-43"><a href="analysis-study-1.html#cb90-43"></a>  )</span></code></pre></div>
Overall, the traceplots look fine and the chains seem to have mixed well (Figure <a href="#fig:inspect-model5-study1"><strong>??</strong></a>).
Like before, the variance around the day grouping is small and mostly estimated to be zero or close to zero.
<div class="figure"><span id="fig:inspect-model5-study1-1"></span>
<img src="analysis_report_files/figure-html/inspect-model5-study1-1.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.32: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model5-study1-2"></span>
<img src="analysis_report_files/figure-html/inspect-model5-study1-2.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.33: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model5-study1-3"></span>
<img src="analysis_report_files/figure-html/inspect-model5-study1-3.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.34: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model5-study1-4"></span>
<img src="analysis_report_files/figure-html/inspect-model5-study1-4.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.35: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model5-study1-5"></span>
<img src="analysis_report_files/figure-html/inspect-model5-study1-5.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.36: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model5-study1-6"></span>
<img src="analysis_report_files/figure-html/inspect-model5-study1-6.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.37: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model5-study1-7"></span>
<img src="analysis_report_files/figure-html/inspect-model5-study1-7.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.38: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model5-study1-8"></span>
<img src="analysis_report_files/figure-html/inspect-model5-study1-8.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.39: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model5-study1-9"></span>
<img src="analysis_report_files/figure-html/inspect-model5-study1-9.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.40: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model5-study1-10"></span>
<img src="analysis_report_files/figure-html/inspect-model5-study1-10.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.41: Traceplots and posterior distributions for Model 4
</p>
</div>
<div class="figure"><span id="fig:inspect-model5-study1-11"></span>
<img src="analysis_report_files/figure-html/inspect-model5-study1-11.png" alt="Traceplots and posterior distributions for Model 4" width="672" />
<p class="caption">
Figure 4.42: Traceplots and posterior distributions for Model 4
</p>
</div>
The posterior predictive check shows about the same model fit as Model 4: mediocre.
It overestimates the frequency of low values compared to the raw data.
I could change the prior, but I also don’t want to overfit just based on the raw data.
<div class="figure"><span id="fig:ppc-model5-study1"></span>
<img src="analysis_report_files/figure-html/ppc-model5-study1-1.png" alt="Posterior predictive checks for Model 5" width="672" />
<p class="caption">
Figure 4.43: Posterior predictive checks for Model 5
</p>
</div>
<p>There are no cases flagged as potentially influential outliers.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="analysis-study-1.html#cb91-1"></a><span class="kw">loo</span>(model5)</span></code></pre></div>
<p>Let’s inspect the summary.
Having an enjoyable and boring day might be related to estimating more social media use (on the between level).
Conversely, a feeling of competence might decrease estimates.
However, all three of those posterior distributions include zero, even though it’s close.</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="analysis-study-1.html#cb92-1"></a><span class="kw">summary</span>(model5, <span class="dt">priors =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>##  Family: gamma 
##   Links: mu = log; shape = identity 
## Formula: social_media_subjective + 1e-06 ~ 1 + autonomy_state_between + competence_state_between + relatedness_state_between + satisfied_between + boring_between + stressful_between + enjoyable_between + autonomy_state_within + competence_state_within + relatedness_state_within + satisfied_within + boring_within + stressful_within + enjoyable_within + (1 + autonomy_state_within + competence_state_within + relatedness_state_within + satisfied_within + boring_within + stressful_within + enjoyable_within | id) + (1 | day) 
##    Data: study1 (Number of observations: 426) 
## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Priors: 
## b ~ normal(0, 0.1)
## Intercept ~ normal(4.5, 0.8)
## L ~ lkj_corr_cholesky(1)
## sd ~ student_t(3, 0, 2.5)
## shape ~ gamma(2.5, 100)
## 
## Group-Level Effects: 
## ~day (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.09      0.10     0.00     0.36 1.00     5313     5438
## 
## ~id (Number of levels: 95) 
##                                                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)                                             0.22      0.13     0.02     0.50 1.00     2231     4226
## sd(autonomy_state_within)                                 0.07      0.06     0.00     0.21 1.00     7775     4772
## sd(competence_state_within)                               0.07      0.05     0.00     0.20 1.00     8686     5040
## sd(relatedness_state_within)                              0.09      0.07     0.00     0.27 1.00     8907     5860
## sd(satisfied_within)                                      0.06      0.05     0.00     0.18 1.00     9133     6252
## sd(boring_within)                                         0.05      0.04     0.00     0.14 1.00     9027     5517
## sd(stressful_within)                                      0.05      0.04     0.00     0.13 1.00     9312     5896
## sd(enjoyable_within)                                      0.06      0.04     0.00     0.16 1.00     7579     4761
## cor(Intercept,autonomy_state_within)                     -0.01      0.33    -0.64     0.62 1.00    18748     8288
## cor(Intercept,competence_state_within)                   -0.01      0.33    -0.64     0.63 1.00    19023     8364
## cor(autonomy_state_within,competence_state_within)       -0.03      0.34    -0.66     0.62 1.00    12652     8850
## cor(Intercept,relatedness_state_within)                   0.01      0.33    -0.62     0.64 1.00    17437     9109
## cor(autonomy_state_within,relatedness_state_within)      -0.02      0.33    -0.64     0.62 1.00    14396     8708
## cor(competence_state_within,relatedness_state_within)    -0.02      0.34    -0.66     0.62 1.00    12050     9396
## cor(Intercept,satisfied_within)                           0.01      0.33    -0.62     0.64 1.00    17277     8231
## cor(autonomy_state_within,satisfied_within)              -0.04      0.33    -0.65     0.60 1.00    13322     8718
## cor(competence_state_within,satisfied_within)            -0.03      0.34    -0.65     0.62 1.00    11019     9231
## cor(relatedness_state_within,satisfied_within)           -0.02      0.34    -0.66     0.63 1.00    10366     9516
## cor(Intercept,boring_within)                              0.01      0.33    -0.64     0.63 1.00    16965     8993
## cor(autonomy_state_within,boring_within)                  0.02      0.33    -0.62     0.64 1.00    14190     9230
## cor(competence_state_within,boring_within)                0.01      0.33    -0.63     0.63 1.00    11525     9319
## cor(relatedness_state_within,boring_within)               0.01      0.33    -0.63     0.64 1.00    10302     9142
## cor(satisfied_within,boring_within)                       0.02      0.34    -0.63     0.65 1.00     8933     8429
## cor(Intercept,stressful_within)                           0.01      0.33    -0.63     0.65 1.00    17141     8427
## cor(autonomy_state_within,stressful_within)               0.03      0.34    -0.61     0.65 1.00    13621     8713
## cor(competence_state_within,stressful_within)             0.03      0.33    -0.61     0.65 1.00    12216     9376
## cor(relatedness_state_within,stressful_within)            0.02      0.33    -0.62     0.64 1.00     9816     9422
## cor(satisfied_within,stressful_within)                    0.01      0.34    -0.63     0.64 1.00     8673     8608
## cor(boring_within,stressful_within)                      -0.01      0.33    -0.64     0.62 1.00     8089     9363
## cor(Intercept,enjoyable_within)                          -0.01      0.33    -0.64     0.62 1.00    16419     8306
## cor(autonomy_state_within,enjoyable_within)              -0.03      0.33    -0.65     0.61 1.00    13723     8204
## cor(competence_state_within,enjoyable_within)            -0.03      0.33    -0.64     0.60 1.00    10569     8524
## cor(relatedness_state_within,enjoyable_within)           -0.03      0.34    -0.66     0.62 1.00    10181     9237
## cor(satisfied_within,enjoyable_within)                   -0.03      0.33    -0.65     0.61 1.00     9344     9643
## cor(boring_within,enjoyable_within)                       0.03      0.33    -0.61     0.65 1.00     8294     9227
## cor(stressful_within,enjoyable_within)                    0.02      0.33    -0.63     0.64 1.00     6549     9256
## 
## Population-Level Effects: 
##                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept                     5.09      0.66     3.81     6.37 1.00    12295     9442
## autonomy_state_between       -0.06      0.08    -0.21     0.09 1.00    13738     8854
## competence_state_between     -0.06      0.07    -0.21     0.08 1.00    12850     9412
## relatedness_state_between     0.02      0.07    -0.12     0.16 1.00    14724     9352
## satisfied_between            -0.07      0.08    -0.22     0.08 1.00    12322     9476
## boring_between                0.08      0.06    -0.03     0.20 1.00    14491     9044
## stressful_between            -0.01      0.05    -0.11     0.09 1.00    12530     8501
## enjoyable_between             0.10      0.07    -0.05     0.24 1.00    12949     9280
## autonomy_state_within        -0.01      0.07    -0.14     0.13 1.00    14017     9265
## competence_state_within      -0.03      0.07    -0.17     0.11 1.00    14816     9115
## relatedness_state_within     -0.00      0.07    -0.15     0.15 1.00    16452     9272
## satisfied_within             -0.02      0.06    -0.15     0.10 1.00    13902     9137
## boring_within                 0.02      0.05    -0.09     0.12 1.00    14976     9244
## stressful_within             -0.01      0.05    -0.11     0.08 1.00    15981     9749
## enjoyable_within              0.02      0.06    -0.10     0.15 1.00    13938     9618
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## shape     0.61      0.04     0.54     0.69 1.00    10365     8891
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
The effects plot (Figure <a href="analysis-study-1.html#fig:effects-model5-study1">4.44</a>) visually that those three states might be influential, but their CIs overlap with zero.
<div class="figure"><span id="fig:effects-model5-study1"></span>
<img src="analysis_report_files/figure-html/effects-model5-study1-1.png" alt="Effects plot for Model 5" width="672" />
<p class="caption">
Figure 4.44: Effects plot for Model 5
</p>
</div>
</div>
<div id="model-6-state-variables-predicting-accuracy" class="section level3">
<h3><span class="header-section-number">4.4.3</span> Model 6: State variables predicting accuracy</h3>
<p>For this model, once more it’s hard to choose informed priors.
Therefore, I choose the same skeptical, but weakly regularizing priors as for Model 3, with a student t distribution with fat tails, an intercept that reflects a tendency to overestimate, and slopes that are skeptical of large effects.
For everything else, I’ll use the <code>brms</code> default priors because I don’t have information on what correlation or variances to expect.
Note that I use the priors on the slope for both between and within effects, simply because I don’t have an informed guess about the two being different.</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="analysis-study-1.html#cb94-1"></a>priors_model6 &lt;-<span class="st"> </span></span>
<span id="cb94-2"><a href="analysis-study-1.html#cb94-2"></a><span class="st">  </span><span class="kw">c</span>(</span>
<span id="cb94-3"><a href="analysis-study-1.html#cb94-3"></a>    <span class="co"># intercept</span></span>
<span id="cb94-4"><a href="analysis-study-1.html#cb94-4"></a>    <span class="kw">prior</span>(<span class="kw">student_t</span>(<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb94-5"><a href="analysis-study-1.html#cb94-5"></a>    </span>
<span id="cb94-6"><a href="analysis-study-1.html#cb94-6"></a>    <span class="co"># all other effects</span></span>
<span id="cb94-7"><a href="analysis-study-1.html#cb94-7"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">25</span>), <span class="dt">class =</span> b)</span>
<span id="cb94-8"><a href="analysis-study-1.html#cb94-8"></a>  )</span></code></pre></div>
<p>Let’s run the model.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="analysis-study-1.html#cb95-1"></a>model6 &lt;-<span class="st"> </span></span>
<span id="cb95-2"><a href="analysis-study-1.html#cb95-2"></a><span class="st">  </span><span class="kw">brm</span>(</span>
<span id="cb95-3"><a href="analysis-study-1.html#cb95-3"></a>    <span class="dt">data =</span> study1,</span>
<span id="cb95-4"><a href="analysis-study-1.html#cb95-4"></a>    <span class="dt">family =</span> student,</span>
<span id="cb95-5"><a href="analysis-study-1.html#cb95-5"></a>    <span class="dt">prior =</span> priors_model6,</span>
<span id="cb95-6"><a href="analysis-study-1.html#cb95-6"></a>    error <span class="op">~</span></span>
<span id="cb95-7"><a href="analysis-study-1.html#cb95-7"></a><span class="st">      </span><span class="dv">1</span> <span class="op">+</span></span>
<span id="cb95-8"><a href="analysis-study-1.html#cb95-8"></a><span class="st">      </span>autonomy_state_between <span class="op">+</span></span>
<span id="cb95-9"><a href="analysis-study-1.html#cb95-9"></a><span class="st">      </span>competence_state_between <span class="op">+</span></span>
<span id="cb95-10"><a href="analysis-study-1.html#cb95-10"></a><span class="st">      </span>relatedness_state_between <span class="op">+</span></span>
<span id="cb95-11"><a href="analysis-study-1.html#cb95-11"></a><span class="st">      </span>satisfied_between <span class="op">+</span></span>
<span id="cb95-12"><a href="analysis-study-1.html#cb95-12"></a><span class="st">      </span>boring_between <span class="op">+</span></span>
<span id="cb95-13"><a href="analysis-study-1.html#cb95-13"></a><span class="st">      </span>stressful_between <span class="op">+</span></span>
<span id="cb95-14"><a href="analysis-study-1.html#cb95-14"></a><span class="st">      </span>enjoyable_between <span class="op">+</span></span>
<span id="cb95-15"><a href="analysis-study-1.html#cb95-15"></a><span class="st">      </span>autonomy_state_within <span class="op">+</span></span>
<span id="cb95-16"><a href="analysis-study-1.html#cb95-16"></a><span class="st">      </span>competence_state_within <span class="op">+</span></span>
<span id="cb95-17"><a href="analysis-study-1.html#cb95-17"></a><span class="st">      </span>relatedness_state_within <span class="op">+</span></span>
<span id="cb95-18"><a href="analysis-study-1.html#cb95-18"></a><span class="st">      </span>satisfied_within <span class="op">+</span></span>
<span id="cb95-19"><a href="analysis-study-1.html#cb95-19"></a><span class="st">      </span>boring_within <span class="op">+</span></span>
<span id="cb95-20"><a href="analysis-study-1.html#cb95-20"></a><span class="st">      </span>stressful_within <span class="op">+</span></span>
<span id="cb95-21"><a href="analysis-study-1.html#cb95-21"></a><span class="st">      </span>enjoyable_within <span class="op">+</span></span>
<span id="cb95-22"><a href="analysis-study-1.html#cb95-22"></a><span class="st">      </span>(</span>
<span id="cb95-23"><a href="analysis-study-1.html#cb95-23"></a>        <span class="dv">1</span> <span class="op">+</span></span>
<span id="cb95-24"><a href="analysis-study-1.html#cb95-24"></a><span class="st">        </span>autonomy_state_within <span class="op">+</span></span>
<span id="cb95-25"><a href="analysis-study-1.html#cb95-25"></a><span class="st">        </span>competence_state_within <span class="op">+</span></span>
<span id="cb95-26"><a href="analysis-study-1.html#cb95-26"></a><span class="st">        </span>relatedness_state_within <span class="op">+</span></span>
<span id="cb95-27"><a href="analysis-study-1.html#cb95-27"></a><span class="st">        </span>satisfied_within <span class="op">+</span></span>
<span id="cb95-28"><a href="analysis-study-1.html#cb95-28"></a><span class="st">        </span>boring_within <span class="op">+</span></span>
<span id="cb95-29"><a href="analysis-study-1.html#cb95-29"></a><span class="st">        </span>stressful_within <span class="op">+</span></span>
<span id="cb95-30"><a href="analysis-study-1.html#cb95-30"></a><span class="st">        </span>enjoyable_within <span class="op">|</span></span>
<span id="cb95-31"><a href="analysis-study-1.html#cb95-31"></a><span class="st">        </span>id</span>
<span id="cb95-32"><a href="analysis-study-1.html#cb95-32"></a>      ) <span class="op">+</span></span>
<span id="cb95-33"><a href="analysis-study-1.html#cb95-33"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span>day),</span>
<span id="cb95-34"><a href="analysis-study-1.html#cb95-34"></a>    <span class="dt">iter =</span> <span class="dv">5000</span>,</span>
<span id="cb95-35"><a href="analysis-study-1.html#cb95-35"></a>    <span class="dt">warmup =</span> <span class="dv">2000</span>,</span>
<span id="cb95-36"><a href="analysis-study-1.html#cb95-36"></a>    <span class="dt">chains =</span> <span class="dv">4</span>,</span>
<span id="cb95-37"><a href="analysis-study-1.html#cb95-37"></a>    <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb95-38"><a href="analysis-study-1.html#cb95-38"></a>    <span class="dt">seed =</span> <span class="dv">42</span>,</span>
<span id="cb95-39"><a href="analysis-study-1.html#cb95-39"></a>    <span class="dt">control =</span> <span class="kw">list</span>(</span>
<span id="cb95-40"><a href="analysis-study-1.html#cb95-40"></a>      <span class="dt">adapt_delta =</span> <span class="fl">0.99</span></span>
<span id="cb95-41"><a href="analysis-study-1.html#cb95-41"></a>    ),</span>
<span id="cb95-42"><a href="analysis-study-1.html#cb95-42"></a>    <span class="dt">file =</span> <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model6_study1&quot;</span>)</span>
<span id="cb95-43"><a href="analysis-study-1.html#cb95-43"></a>  )</span></code></pre></div>
Overall, the traceplots look fine and the chains seem to have mixed well, see (Figure <a href="#fig:inspect-model6-study1"><strong>??</strong></a>), just like with Model 3.
<div class="figure"><span id="fig:inspect-model6-study1-1"></span>
<img src="analysis_report_files/figure-html/inspect-model6-study1-1.png" alt="Traceplots and posterior distributions for Model 6" width="672" />
<p class="caption">
Figure 4.45: Traceplots and posterior distributions for Model 6
</p>
</div>
<div class="figure"><span id="fig:inspect-model6-study1-2"></span>
<img src="analysis_report_files/figure-html/inspect-model6-study1-2.png" alt="Traceplots and posterior distributions for Model 6" width="672" />
<p class="caption">
Figure 4.46: Traceplots and posterior distributions for Model 6
</p>
</div>
<div class="figure"><span id="fig:inspect-model6-study1-3"></span>
<img src="analysis_report_files/figure-html/inspect-model6-study1-3.png" alt="Traceplots and posterior distributions for Model 6" width="672" />
<p class="caption">
Figure 4.47: Traceplots and posterior distributions for Model 6
</p>
</div>
<div class="figure"><span id="fig:inspect-model6-study1-4"></span>
<img src="analysis_report_files/figure-html/inspect-model6-study1-4.png" alt="Traceplots and posterior distributions for Model 6" width="672" />
<p class="caption">
Figure 4.48: Traceplots and posterior distributions for Model 6
</p>
</div>
<div class="figure"><span id="fig:inspect-model6-study1-5"></span>
<img src="analysis_report_files/figure-html/inspect-model6-study1-5.png" alt="Traceplots and posterior distributions for Model 6" width="672" />
<p class="caption">
Figure 4.49: Traceplots and posterior distributions for Model 6
</p>
</div>
<div class="figure"><span id="fig:inspect-model6-study1-6"></span>
<img src="analysis_report_files/figure-html/inspect-model6-study1-6.png" alt="Traceplots and posterior distributions for Model 6" width="672" />
<p class="caption">
Figure 4.50: Traceplots and posterior distributions for Model 6
</p>
</div>
<div class="figure"><span id="fig:inspect-model6-study1-7"></span>
<img src="analysis_report_files/figure-html/inspect-model6-study1-7.png" alt="Traceplots and posterior distributions for Model 6" width="672" />
<p class="caption">
Figure 4.51: Traceplots and posterior distributions for Model 6
</p>
</div>
<div class="figure"><span id="fig:inspect-model6-study1-8"></span>
<img src="analysis_report_files/figure-html/inspect-model6-study1-8.png" alt="Traceplots and posterior distributions for Model 6" width="672" />
<p class="caption">
Figure 4.52: Traceplots and posterior distributions for Model 6
</p>
</div>
<div class="figure"><span id="fig:inspect-model6-study1-9"></span>
<img src="analysis_report_files/figure-html/inspect-model6-study1-9.png" alt="Traceplots and posterior distributions for Model 6" width="672" />
<p class="caption">
Figure 4.53: Traceplots and posterior distributions for Model 6
</p>
</div>
<div class="figure"><span id="fig:inspect-model6-study1-10"></span>
<img src="analysis_report_files/figure-html/inspect-model6-study1-10.png" alt="Traceplots and posterior distributions for Model 6" width="672" />
<p class="caption">
Figure 4.54: Traceplots and posterior distributions for Model 6
</p>
</div>
<div class="figure"><span id="fig:inspect-model6-study1-11"></span>
<img src="analysis_report_files/figure-html/inspect-model6-study1-11.png" alt="Traceplots and posterior distributions for Model 6" width="672" />
<p class="caption">
Figure 4.55: Traceplots and posterior distributions for Model 6
</p>
</div>
The posterior predictive checks (Figure <a href="#fig:ppc-model6-study1"><strong>??</strong></a>) look good.
Like with Model 3, that the upper left panel looks strange because of the massive scale on the x-axis.
I reproduce it again at the bottom with a more sensible x-axis.
Once more, the student t distribution assigns too much posterior mass to negative values, whereas the data are right skewed.
Otherwise, the model does an okay job in recovering the mean and the median.
<div class="figure"><span id="fig:ppc-model6-study1-1"></span>
<img src="analysis_report_files/figure-html/ppc-model6-study1-1.png" alt="Posterior predictive checks for Model 6" width="672" />
<p class="caption">
Figure 4.56: Posterior predictive checks for Model 6
</p>
</div>
<div class="figure"><span id="fig:ppc-model6-study1-2"></span>
<img src="analysis_report_files/figure-html/ppc-model6-study1-2.png" alt="Posterior predictive checks for Model 6" width="672" />
<p class="caption">
Figure 4.57: Posterior predictive checks for Model 6
</p>
</div>
<p>Two cases are flagged as potential outliers.</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="analysis-study-1.html#cb96-1"></a>model6_loo &lt;-<span class="st"> </span><span class="kw">loo</span>(model6, <span class="dt">reloo =</span> <span class="ot">TRUE</span>)</span>
<span id="cb96-2"><a href="analysis-study-1.html#cb96-2"></a><span class="kw">saveRDS</span>(model6_loo, <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model6_loo_study1.rds&quot;</span>))</span></code></pre></div>
<p>I’ll calculate them directly and they’re fine.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="analysis-study-1.html#cb97-1"></a>model6_loo &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model6_loo_study1.rds&quot;</span>))</span>
<span id="cb97-2"><a href="analysis-study-1.html#cb97-2"></a>model6_loo</span></code></pre></div>
<pre><code>## 
## Computed from 12000 by 424 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo  -2391.9 30.5
## p_loo       213.1  8.1
## looic      4783.8 61.0
## ------
## Monte Carlo SE of elpd_loo is 0.2.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     423   99.8%   206       
##  (0.5, 0.7]   (ok)         1    0.2%   1815      
##    (0.7, 1]   (bad)        0    0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>Let’s inspect the summary.
All posteriors include 0, only satisfaction (within) comes close.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="analysis-study-1.html#cb99-1"></a><span class="kw">summary</span>(model6, <span class="dt">priors =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>##  Family: student 
##   Links: mu = identity; sigma = identity; nu = identity 
## Formula: error ~ 1 + autonomy_state_between + competence_state_between + relatedness_state_between + satisfied_between + boring_between + stressful_between + enjoyable_between + autonomy_state_within + competence_state_within + relatedness_state_within + satisfied_within + boring_within + stressful_within + enjoyable_within + (1 + autonomy_state_within + competence_state_within + relatedness_state_within + satisfied_within + boring_within + stressful_within + enjoyable_within | id) + (1 | day) 
##    Data: study1 (Number of observations: 424) 
## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Priors: 
## b ~ normal(0, 25)
## Intercept ~ student_t(10, 20, 100)
## L ~ lkj_corr_cholesky(1)
## nu ~ gamma(2, 0.1)
## sd ~ student_t(3, 0, 57.8)
## sigma ~ student_t(3, 0, 57.8)
## 
## Group-Level Effects: 
## ~day (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     3.41      3.66     0.11    12.84 1.00     6476     6100
## 
## ~id (Number of levels: 95) 
##                                                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)                                            64.38      6.23    53.24    77.66 1.00     2840     5247
## sd(autonomy_state_within)                                 5.85      3.93     0.28    14.72 1.00     3473     5614
## sd(competence_state_within)                               3.66      2.77     0.15    10.44 1.00     5771     7535
## sd(relatedness_state_within)                              9.63      6.56     0.43    24.07 1.00     2133     3920
## sd(satisfied_within)                                      7.24      4.11     0.47    15.96 1.00     2136     3988
## sd(boring_within)                                         2.71      2.12     0.09     7.89 1.00     4524     6268
## sd(stressful_within)                                      4.91      3.30     0.23    12.10 1.00     1890     3755
## sd(enjoyable_within)                                      3.20      2.52     0.14     9.46 1.00     4313     6103
## cor(Intercept,autonomy_state_within)                      0.02      0.31    -0.58     0.60 1.00    14838     8308
## cor(Intercept,competence_state_within)                    0.02      0.33    -0.62     0.64 1.00    19070     8942
## cor(autonomy_state_within,competence_state_within)       -0.06      0.34    -0.69     0.61 1.00    14439     9787
## cor(Intercept,relatedness_state_within)                  -0.10      0.30    -0.65     0.53 1.00     9073     9158
## cor(autonomy_state_within,relatedness_state_within)      -0.06      0.33    -0.67     0.59 1.00     6576     7883
## cor(competence_state_within,relatedness_state_within)    -0.01      0.33    -0.62     0.63 1.00     7232     8824
## cor(Intercept,satisfied_within)                          -0.23      0.28    -0.71     0.38 1.00    10306     7770
## cor(autonomy_state_within,satisfied_within)              -0.03      0.33    -0.65     0.61 1.00     6597     8654
## cor(competence_state_within,satisfied_within)            -0.04      0.33    -0.66     0.61 1.00     6986     8688
## cor(relatedness_state_within,satisfied_within)           -0.04      0.33    -0.65     0.60 1.00     6245     9193
## cor(Intercept,boring_within)                              0.01      0.33    -0.61     0.64 1.00    16704     8082
## cor(autonomy_state_within,boring_within)                  0.00      0.33    -0.63     0.63 1.00    12657     9964
## cor(competence_state_within,boring_within)                0.03      0.33    -0.61     0.65 1.00    11823     9555
## cor(relatedness_state_within,boring_within)              -0.02      0.33    -0.65     0.63 1.00    12117    10280
## cor(satisfied_within,boring_within)                       0.00      0.33    -0.62     0.63 1.00    12156    10613
## cor(Intercept,stressful_within)                           0.03      0.30    -0.56     0.58 1.00    12474     8714
## cor(autonomy_state_within,stressful_within)               0.05      0.33    -0.58     0.66 1.00     6952     8213
## cor(competence_state_within,stressful_within)             0.01      0.33    -0.62     0.64 1.00     6700     7870
## cor(relatedness_state_within,stressful_within)            0.03      0.33    -0.60     0.64 1.00     7192     8518
## cor(satisfied_within,stressful_within)                   -0.03      0.32    -0.63     0.59 1.00     7474     9271
## cor(boring_within,stressful_within)                      -0.02      0.33    -0.65     0.61 1.00     7225     9434
## cor(Intercept,enjoyable_within)                          -0.02      0.32    -0.62     0.59 1.00    15825     9934
## cor(autonomy_state_within,enjoyable_within)              -0.03      0.33    -0.65     0.62 1.00    13401    10188
## cor(competence_state_within,enjoyable_within)            -0.04      0.34    -0.67     0.61 1.00    11477    10684
## cor(relatedness_state_within,enjoyable_within)           -0.04      0.34    -0.66     0.60 1.00    11328    10108
## cor(satisfied_within,enjoyable_within)                   -0.06      0.33    -0.67     0.60 1.00    12103    10485
## cor(boring_within,enjoyable_within)                       0.05      0.34    -0.61     0.67 1.00     8012     9968
## cor(stressful_within,enjoyable_within)                    0.02      0.34    -0.63     0.65 1.00    10181    10927
## 
## Population-Level Effects: 
##                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept                    63.31     78.82   -91.24   219.46 1.00     2859     5281
## autonomy_state_between       -6.76     11.13   -28.76    14.82 1.00     3177     5453
## competence_state_between     -5.69     10.06   -25.53    14.16 1.00     2876     5393
## relatedness_state_between     5.92      9.74   -13.25    24.67 1.00     2896     5522
## satisfied_between           -10.75     11.64   -33.38    12.27 1.00     3308     5120
## boring_between                3.33      6.98   -10.37    17.10 1.00     3046     5394
## stressful_between            -5.32      6.11   -17.32     6.75 1.00     2657     5299
## enjoyable_between             7.11     11.64   -15.85    30.23 1.00     3090     4888
## autonomy_state_within        -0.77      3.24    -7.15     5.34 1.00    10936     9433
## competence_state_within       0.09      3.10    -5.99     6.21 1.00    11169    10175
## relatedness_state_within      0.98      4.13    -7.28     9.10 1.00     8348     8765
## satisfied_within             -5.59      2.98   -11.41     0.27 1.00     9472     9401
## boring_within                 2.31      1.94    -1.40     6.21 1.00     9277     9113
## stressful_within             -0.42      1.89    -4.07     3.36 1.00    10267     9302
## enjoyable_within              2.21      2.40    -2.45     6.99 1.00     9500     8490
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    19.87      2.44    15.42    24.95 1.00     2682     5049
## nu        1.17      0.12     1.01     1.44 1.00     5473     5046
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
The effects plot (Figure <a href="analysis-study-1.html#fig:effects-model6-study1">4.58</a>) visually confirms what I wrote above.
Note the difference in scale: everything except the correlations are in percent error, whereas the correlations are on their -1 to 1 scale.
<div class="figure"><span id="fig:effects-model6-study1"></span>
<img src="analysis_report_files/figure-html/effects-model6-study1-1.png" alt="Effects plot for Model 6" width="672" />
<p class="caption">
Figure 4.58: Effects plot for Model 6
</p>
</div>
</div>
</div>
<div id="does-social-media-use-predict-well-being" class="section level2">
<h2><span class="header-section-number">4.5</span> Does social media use predict well-being?</h2>
<p>For this RQ, we have three questions blocks.
We want to know how day-level social media use (both types) and accuracy are related to well-being.</p>
<p>The three questions are:
1. Does objective-only engagement predict day-level well-being?
2. Does subjective-only engagement predict day-level well-being?
3. Does accuracy predict day-level well-being?</p>
<div id="model-7-objective-use-predicting-well-being" class="section level3">
<h3><span class="header-section-number">4.5.1</span> Model 7: Objective use predicting well-being</h3>
<p>For this model, we’ll predict well-being on that day with objective social media use on that day.
Priors here can be controversial, depending on what literature we look to.
Well-being is often left-skewed, so we could go for a skewed normal distribution for the model.
However, that might be too strong an assumption, which is why I’ll use a model that assumes a normal Gaussian distribution.</p>
<p>As for the specific priors:</p>
<ul>
<li>When social media use is at zero between people and at zero within, I’ll simply assume a normal distribution centered on the midpoint of the scale (i.e., 3).
As for the SD of that distribution, we know the bounds of the scale, so an SD of 1 will have 95% of cases within 1 and 5, which is exactly what we want.</li>
<li>As for the slopes: There are two papers I know of that found a negative, small effect, but another paper that found a negligent one.
The larger literature on self-reported media use and well-being also finds very small negative effects, in the range of <span class="math inline">\(\beta\)</span> = .05.
We’re on the unstandardized scale here.
So if we assume that well-being is at the midpoint of the scale (i.e., 3), the maximum effect an increase in social media time could have is to bring well-being to its ceiling or floor.
That would imply a standard deviation of 1 again - that depends on the scale of the predictor, though.
Right now, it’s in minutes and we’d need to scale the prior accordingly.
This <a href="https://www.tandfonline.com/doi/full/10.1080/15213269.2020.1768122">paper</a> found that with each increase of one standard deviation in social media time, well-being on a 7-point Likert-scale went down by -.06 units.
The standard deviation was 190.
Therefore (with some crude math), one hour of social media use was associated with <code>190/60 * -.06</code> = -0.19 raw units on the outcome scale.
From the literature we also know that massive (unstandardized) effects are rare if impossible.
Therefore, I’ll center the slope distribution on a small negative value.
To be conservative, I’ll take about 75% of the -.19 we found above (say -0.15 Likert-scales) with a somewhat tight standard deviation (say 0.3).
This way, 95% of effects will be within -.75 (-.15 + (2 times 0.2)) and 0.45 Likert-points on the outcome scale.
Note that we’re on the between-level here: a user with one more hour of social media use will report, on average, a .15 lower score on well-being than someone else with an hour less.</li>
<li>As for the within-effect, most research points toward negligible within-effects, and all of them are on self-reported media use.
So here I’ll assume a slopes that varies around zero, but I’ll allow a wider standard deviation than for the between-effect, 0.4.
That way, the average within-person effect will be zero and it assumes that 95% of effects are within -0.8 and + 0.8 Likert-points.</li>
<li>For everything else, I’ll once more go with the default <code>brms</code> priors.</li>
</ul>
<p>Let’s set those priors.
Note that we’re still on the minute scale for the predictor, but I specified priors above for hours.
That’s why I transform the social media variables to hours (and center) to make interpretation easier.
That also helps us set the priors we specified above.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="analysis-study-1.html#cb101-1"></a><span class="co"># create hour variables</span></span>
<span id="cb101-2"><a href="analysis-study-1.html#cb101-2"></a>study1 &lt;-<span class="st"> </span></span>
<span id="cb101-3"><a href="analysis-study-1.html#cb101-3"></a><span class="st">  </span>study1 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb101-4"><a href="analysis-study-1.html#cb101-4"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb101-5"><a href="analysis-study-1.html#cb101-5"></a>    <span class="kw">across</span>(</span>
<span id="cb101-6"><a href="analysis-study-1.html#cb101-6"></a>      <span class="kw">c</span>(social_media_objective, social_media_subjective),</span>
<span id="cb101-7"><a href="analysis-study-1.html#cb101-7"></a>      <span class="op">~</span><span class="st"> </span>.x <span class="op">/</span><span class="st"> </span><span class="dv">60</span>, <span class="co">#  divide by 60 to get hours</span></span>
<span id="cb101-8"><a href="analysis-study-1.html#cb101-8"></a>      <span class="dt">.names =</span> <span class="st">&quot;{col}_hours&quot;</span></span>
<span id="cb101-9"><a href="analysis-study-1.html#cb101-9"></a>    )</span>
<span id="cb101-10"><a href="analysis-study-1.html#cb101-10"></a>  )</span>
<span id="cb101-11"><a href="analysis-study-1.html#cb101-11"></a></span>
<span id="cb101-12"><a href="analysis-study-1.html#cb101-12"></a><span class="co"># center to get between and within variables</span></span>
<span id="cb101-13"><a href="analysis-study-1.html#cb101-13"></a>study1 &lt;-<span class="st"> </span></span>
<span id="cb101-14"><a href="analysis-study-1.html#cb101-14"></a><span class="st">  </span>study1 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb101-15"><a href="analysis-study-1.html#cb101-15"></a><span class="st">  </span><span class="kw">group_by</span>(id) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb101-16"><a href="analysis-study-1.html#cb101-16"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb101-17"><a href="analysis-study-1.html#cb101-17"></a>    <span class="kw">across</span>(</span>
<span id="cb101-18"><a href="analysis-study-1.html#cb101-18"></a>      <span class="kw">ends_with</span>(<span class="st">&quot;hours&quot;</span>),</span>
<span id="cb101-19"><a href="analysis-study-1.html#cb101-19"></a>      <span class="kw">list</span>(</span>
<span id="cb101-20"><a href="analysis-study-1.html#cb101-20"></a>        <span class="dt">between =</span> <span class="op">~</span><span class="st"> </span><span class="kw">mean</span>(.x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),</span>
<span id="cb101-21"><a href="analysis-study-1.html#cb101-21"></a>        <span class="dt">within =</span> <span class="op">~</span>.x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(.x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</span>
<span id="cb101-22"><a href="analysis-study-1.html#cb101-22"></a>      )</span>
<span id="cb101-23"><a href="analysis-study-1.html#cb101-23"></a>    )</span>
<span id="cb101-24"><a href="analysis-study-1.html#cb101-24"></a>  ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb101-25"><a href="analysis-study-1.html#cb101-25"></a><span class="st">  </span><span class="kw">ungroup</span>()</span>
<span id="cb101-26"><a href="analysis-study-1.html#cb101-26"></a></span>
<span id="cb101-27"><a href="analysis-study-1.html#cb101-27"></a><span class="co"># set priors</span></span>
<span id="cb101-28"><a href="analysis-study-1.html#cb101-28"></a>priors_model7 &lt;-<span class="st"> </span></span>
<span id="cb101-29"><a href="analysis-study-1.html#cb101-29"></a><span class="st">  </span><span class="kw">c</span>(</span>
<span id="cb101-30"><a href="analysis-study-1.html#cb101-30"></a>    <span class="co"># intercept</span></span>
<span id="cb101-31"><a href="analysis-study-1.html#cb101-31"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">3</span>, <span class="dv">1</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb101-32"><a href="analysis-study-1.html#cb101-32"></a>    </span>
<span id="cb101-33"><a href="analysis-study-1.html#cb101-33"></a>    <span class="co"># slopes for between</span></span>
<span id="cb101-34"><a href="analysis-study-1.html#cb101-34"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="op">-</span><span class="fl">0.15</span>, <span class="fl">0.30</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> <span class="st">&quot;social_media_objective_hours_between&quot;</span>),</span>
<span id="cb101-35"><a href="analysis-study-1.html#cb101-35"></a>    </span>
<span id="cb101-36"><a href="analysis-study-1.html#cb101-36"></a>    <span class="co"># slopes for between</span></span>
<span id="cb101-37"><a href="analysis-study-1.html#cb101-37"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.40</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> <span class="st">&quot;social_media_objective_hours_within&quot;</span>)</span>
<span id="cb101-38"><a href="analysis-study-1.html#cb101-38"></a>  )</span></code></pre></div>
<p>Okay, let’s run the model.</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="analysis-study-1.html#cb102-1"></a>model7 &lt;-<span class="st"> </span></span>
<span id="cb102-2"><a href="analysis-study-1.html#cb102-2"></a><span class="st">  </span><span class="kw">brm</span>(</span>
<span id="cb102-3"><a href="analysis-study-1.html#cb102-3"></a>    <span class="dt">data =</span> study1,</span>
<span id="cb102-4"><a href="analysis-study-1.html#cb102-4"></a>    <span class="dt">family =</span> gaussian,</span>
<span id="cb102-5"><a href="analysis-study-1.html#cb102-5"></a>    <span class="dt">prior =</span> priors_model7,</span>
<span id="cb102-6"><a href="analysis-study-1.html#cb102-6"></a>    well_being_state <span class="op">~</span></span>
<span id="cb102-7"><a href="analysis-study-1.html#cb102-7"></a><span class="st">      </span><span class="dv">1</span> <span class="op">+</span></span>
<span id="cb102-8"><a href="analysis-study-1.html#cb102-8"></a><span class="st">      </span>social_media_objective_hours_between <span class="op">+</span></span>
<span id="cb102-9"><a href="analysis-study-1.html#cb102-9"></a><span class="st">      </span>social_media_objective_hours_within <span class="op">+</span></span>
<span id="cb102-10"><a href="analysis-study-1.html#cb102-10"></a><span class="st">      </span>(</span>
<span id="cb102-11"><a href="analysis-study-1.html#cb102-11"></a>        <span class="dv">1</span> <span class="op">+</span></span>
<span id="cb102-12"><a href="analysis-study-1.html#cb102-12"></a><span class="st">        </span>social_media_objective_hours_within <span class="op">|</span></span>
<span id="cb102-13"><a href="analysis-study-1.html#cb102-13"></a><span class="st">        </span>id</span>
<span id="cb102-14"><a href="analysis-study-1.html#cb102-14"></a>      ) <span class="op">+</span></span>
<span id="cb102-15"><a href="analysis-study-1.html#cb102-15"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span>day),</span>
<span id="cb102-16"><a href="analysis-study-1.html#cb102-16"></a>    <span class="dt">iter =</span> <span class="dv">5000</span>,</span>
<span id="cb102-17"><a href="analysis-study-1.html#cb102-17"></a>    <span class="dt">warmup =</span> <span class="dv">2000</span>,</span>
<span id="cb102-18"><a href="analysis-study-1.html#cb102-18"></a>    <span class="dt">chains =</span> <span class="dv">4</span>,</span>
<span id="cb102-19"><a href="analysis-study-1.html#cb102-19"></a>    <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb102-20"><a href="analysis-study-1.html#cb102-20"></a>    <span class="dt">seed =</span> <span class="dv">42</span>,</span>
<span id="cb102-21"><a href="analysis-study-1.html#cb102-21"></a>    <span class="dt">control =</span> <span class="kw">list</span>(</span>
<span id="cb102-22"><a href="analysis-study-1.html#cb102-22"></a>      <span class="dt">adapt_delta =</span> <span class="fl">0.99</span></span>
<span id="cb102-23"><a href="analysis-study-1.html#cb102-23"></a>    ),</span>
<span id="cb102-24"><a href="analysis-study-1.html#cb102-24"></a>    <span class="dt">file =</span> <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model7_study1&quot;</span>)</span>
<span id="cb102-25"><a href="analysis-study-1.html#cb102-25"></a>  )</span></code></pre></div>
Overall, the traceplots look fine and the chains seem to have mixed well, see (Figure <a href="#fig:inspect-model7-study1"><strong>??</strong></a>).
<div class="figure"><span id="fig:inspect-model7-study1-1"></span>
<img src="analysis_report_files/figure-html/inspect-model7-study1-1.png" alt="Traceplots and posterior distributions for Model 7" width="672" />
<p class="caption">
Figure 4.59: Traceplots and posterior distributions for Model 7
</p>
</div>
<div class="figure"><span id="fig:inspect-model7-study1-2"></span>
<img src="analysis_report_files/figure-html/inspect-model7-study1-2.png" alt="Traceplots and posterior distributions for Model 7" width="672" />
<p class="caption">
Figure 4.60: Traceplots and posterior distributions for Model 7
</p>
</div>
The posterior predictive checks (Figure <a href="analysis-study-1.html#fig:ppc-model7-study1">4.61</a>) look excellent (no surprise with only one predictor).
<div class="figure"><span id="fig:ppc-model7-study1"></span>
<img src="analysis_report_files/figure-html/ppc-model7-study1-1.png" alt="Posterior predictive checks for Model 7" width="672" />
<p class="caption">
Figure 4.61: Posterior predictive checks for Model 7
</p>
</div>
<p>Two cases are flagged as potentially influential cases.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="analysis-study-1.html#cb103-1"></a>model7_loo &lt;-<span class="st"> </span><span class="kw">loo</span>(model7, <span class="dt">reloo =</span> <span class="ot">TRUE</span>)</span>
<span id="cb103-2"><a href="analysis-study-1.html#cb103-2"></a><span class="kw">saveRDS</span>(model7_loo, <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model7_loo_study1.rds&quot;</span>))</span></code></pre></div>
<p>I’ll calculate them directly and they’re fine.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="analysis-study-1.html#cb104-1"></a>model7_loo &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model7_loo_study1.rds&quot;</span>))</span>
<span id="cb104-2"><a href="analysis-study-1.html#cb104-2"></a>model7_loo</span></code></pre></div>
<pre><code>## 
## Computed from 12000 by 431 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo   -378.1 16.1
## p_loo        79.2  5.2
## looic       756.2 32.1
## ------
## Monte Carlo SE of elpd_loo is 0.2.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     417   96.8%   220       
##  (0.5, 0.7]   (ok)        14    3.2%   1283      
##    (0.7, 1]   (bad)        0    0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>Let’s inspect the summary.
The relation is estimated to be extremely close to zero, so really no interpretative wiggle room there.
I think this is pretty convincing evidence for the lack of an effect.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="analysis-study-1.html#cb106-1"></a><span class="kw">summary</span>(model7, <span class="dt">priors =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: well_being_state ~ 1 + social_media_objective_hours_between + social_media_objective_hours_within + (1 + social_media_objective_hours_within | id) + (1 | day) 
##    Data: study1 (Number of observations: 431) 
## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Priors: 
## b_social_media_objective_hours_between ~ normal(-0.15, 0.3)
## b_social_media_objective_hours_within ~ normal(0, 0.4)
## Intercept ~ normal(3, 1)
## L ~ lkj_corr_cholesky(1)
## sd ~ student_t(3, 0, 2.5)
## sigma ~ student_t(3, 0, 2.5)
## 
## Group-Level Effects: 
## ~day (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.18      0.12     0.06     0.50 1.00     3401     4724
## 
## ~id (Number of levels: 95) 
##                                                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)                                          0.47      0.05     0.39     0.56 1.00     3952     6890
## sd(social_media_objective_hours_within)                0.08      0.05     0.00     0.20 1.00     3046     4835
## cor(Intercept,social_media_objective_hours_within)    -0.05      0.43    -0.89     0.81 1.00     9795     5499
## 
## Population-Level Effects: 
##                                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept                                3.22      0.14     2.94     3.50 1.00     3862     4999
## social_media_objective_hours_between     0.01      0.04    -0.07     0.08 1.00     4115     6259
## social_media_objective_hours_within     -0.01      0.04    -0.09     0.06 1.00    14799     8534
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.52      0.02     0.48     0.57 1.00     9454     8937
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
The effects plot (Figure <a href="analysis-study-1.html#fig:effects-model7-study1">4.62</a>) visually confirms what I wrote above.
<div class="figure"><span id="fig:effects-model7-study1"></span>
<img src="analysis_report_files/figure-html/effects-model7-study1-1.png" alt="Effects plot for Model 7" width="672" />
<p class="caption">
Figure 4.62: Effects plot for Model 7
</p>
</div>
</div>
<div id="model-8-subjective-use-predicting-well-being" class="section level3">
<h3><span class="header-section-number">4.5.2</span> Model 8: Subjective use predicting well-being</h3>
<p>Next, we’ll predict well-being on that day with subjective social media use on that day.
There’s conflicting information in the literature: I’m aware of a paper that says subjective estimates overstate the relation, but of another that says the opposite.
Therefore,</p>
<p>The specific priors:</p>
<ul>
<li>For the intercept, I’ll use the same prior as with Model 7.</li>
<li>As for the slopes: <a href="https://journals.sagepub.com/doi/suppl/10.1177/0956797619830329">This</a> paper reports median effect sizes across all specifications of <span class="math inline">\(\beta\)</span> = -.08, with effect sizes larger on the between-level, but small to negligible on the within-level.
That’s among adolescents and for a longer time frame.
<a href="https://osf.io/mpxra">This</a> explicitly compared subjective to objective and found that subjective is a much stronger predictor (up to four times the effect size).
<a href="https://academic.oup.com/jcmc/article/25/5/346/5896236">This</a> says subjective estimates ever so slightly understimate relations between use and well-being, though.
Overall, I’d say we can expect a somewhat more negative between-person relation, which would lead us to believe a mean negative effect of -.20 Likert-points on well-being and 0.4 standard deviation to allow for more extreme slopes.
That would bring 95% of effects within -1 and 0.6 Likert-points, which is rather generous for media effects.</li>
<li>For the within-effect, I’ll stick to the same prior as for the previous model.</li>
<li>For everything else, I’ll once more go with the default <code>brms</code> priors.</li>
</ul>
<p>Let’s set those priors.</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="analysis-study-1.html#cb108-1"></a><span class="co"># set priors</span></span>
<span id="cb108-2"><a href="analysis-study-1.html#cb108-2"></a>priors_model8 &lt;-<span class="st"> </span></span>
<span id="cb108-3"><a href="analysis-study-1.html#cb108-3"></a><span class="st">  </span><span class="kw">c</span>(</span>
<span id="cb108-4"><a href="analysis-study-1.html#cb108-4"></a>    <span class="co"># intercept</span></span>
<span id="cb108-5"><a href="analysis-study-1.html#cb108-5"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">3</span>, <span class="dv">1</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb108-6"><a href="analysis-study-1.html#cb108-6"></a>    </span>
<span id="cb108-7"><a href="analysis-study-1.html#cb108-7"></a>    <span class="co"># slopes for between</span></span>
<span id="cb108-8"><a href="analysis-study-1.html#cb108-8"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">0.4</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> <span class="st">&quot;social_media_subjective_hours_between&quot;</span>),</span>
<span id="cb108-9"><a href="analysis-study-1.html#cb108-9"></a>    </span>
<span id="cb108-10"><a href="analysis-study-1.html#cb108-10"></a>    <span class="co"># slopes for between</span></span>
<span id="cb108-11"><a href="analysis-study-1.html#cb108-11"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.40</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> <span class="st">&quot;social_media_subjective_hours_within&quot;</span>)</span>
<span id="cb108-12"><a href="analysis-study-1.html#cb108-12"></a>  )</span></code></pre></div>
<p>Okay, let’s run the model.</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="analysis-study-1.html#cb109-1"></a>model8 &lt;-<span class="st"> </span></span>
<span id="cb109-2"><a href="analysis-study-1.html#cb109-2"></a><span class="st">  </span><span class="kw">brm</span>(</span>
<span id="cb109-3"><a href="analysis-study-1.html#cb109-3"></a>    <span class="dt">data =</span> study1,</span>
<span id="cb109-4"><a href="analysis-study-1.html#cb109-4"></a>    <span class="dt">family =</span> gaussian,</span>
<span id="cb109-5"><a href="analysis-study-1.html#cb109-5"></a>    <span class="dt">prior =</span> priors_model8,</span>
<span id="cb109-6"><a href="analysis-study-1.html#cb109-6"></a>    well_being_state <span class="op">~</span></span>
<span id="cb109-7"><a href="analysis-study-1.html#cb109-7"></a><span class="st">      </span><span class="dv">1</span> <span class="op">+</span></span>
<span id="cb109-8"><a href="analysis-study-1.html#cb109-8"></a><span class="st">      </span>social_media_subjective_hours_between <span class="op">+</span></span>
<span id="cb109-9"><a href="analysis-study-1.html#cb109-9"></a><span class="st">      </span>social_media_subjective_hours_within <span class="op">+</span></span>
<span id="cb109-10"><a href="analysis-study-1.html#cb109-10"></a><span class="st">      </span>(</span>
<span id="cb109-11"><a href="analysis-study-1.html#cb109-11"></a>        <span class="dv">1</span> <span class="op">+</span></span>
<span id="cb109-12"><a href="analysis-study-1.html#cb109-12"></a><span class="st">        </span>social_media_subjective_hours_within <span class="op">|</span></span>
<span id="cb109-13"><a href="analysis-study-1.html#cb109-13"></a><span class="st">        </span>id</span>
<span id="cb109-14"><a href="analysis-study-1.html#cb109-14"></a>      ) <span class="op">+</span></span>
<span id="cb109-15"><a href="analysis-study-1.html#cb109-15"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span>day),</span>
<span id="cb109-16"><a href="analysis-study-1.html#cb109-16"></a>    <span class="dt">iter =</span> <span class="dv">5000</span>,</span>
<span id="cb109-17"><a href="analysis-study-1.html#cb109-17"></a>    <span class="dt">warmup =</span> <span class="dv">2000</span>,</span>
<span id="cb109-18"><a href="analysis-study-1.html#cb109-18"></a>    <span class="dt">chains =</span> <span class="dv">4</span>,</span>
<span id="cb109-19"><a href="analysis-study-1.html#cb109-19"></a>    <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb109-20"><a href="analysis-study-1.html#cb109-20"></a>    <span class="dt">seed =</span> <span class="dv">42</span>,</span>
<span id="cb109-21"><a href="analysis-study-1.html#cb109-21"></a>    <span class="dt">control =</span> <span class="kw">list</span>(</span>
<span id="cb109-22"><a href="analysis-study-1.html#cb109-22"></a>      <span class="dt">adapt_delta =</span> <span class="fl">0.99</span></span>
<span id="cb109-23"><a href="analysis-study-1.html#cb109-23"></a>    ),</span>
<span id="cb109-24"><a href="analysis-study-1.html#cb109-24"></a>    <span class="dt">file =</span> <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model8_study1&quot;</span>)</span>
<span id="cb109-25"><a href="analysis-study-1.html#cb109-25"></a>  )</span></code></pre></div>
Overall, the traceplots look fine and the chains seem to have mixed well, see (Figure <a href="#fig:inspect-model8-study1"><strong>??</strong></a>).
<div class="figure"><span id="fig:inspect-model8-study1-1"></span>
<img src="analysis_report_files/figure-html/inspect-model8-study1-1.png" alt="Traceplots and posterior distributions for Model 8" width="672" />
<p class="caption">
Figure 4.63: Traceplots and posterior distributions for Model 8
</p>
</div>
<div class="figure"><span id="fig:inspect-model8-study1-2"></span>
<img src="analysis_report_files/figure-html/inspect-model8-study1-2.png" alt="Traceplots and posterior distributions for Model 8" width="672" />
<p class="caption">
Figure 4.64: Traceplots and posterior distributions for Model 8
</p>
</div>
The posterior predictive checks (Figure <a href="analysis-study-1.html#fig:ppc-model8-study1">4.65</a>) look excellent, just like with Model 7 (no surprise with only one predictor).
<div class="figure"><span id="fig:ppc-model8-study1"></span>
<img src="analysis_report_files/figure-html/ppc-model8-study1-1.png" alt="Posterior predictive checks for Model 8" width="672" />
<p class="caption">
Figure 4.65: Posterior predictive checks for Model 8
</p>
</div>
<p>No case is flagged as potentially influential.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="analysis-study-1.html#cb110-1"></a><span class="kw">loo</span>(model8)</span></code></pre></div>
<pre><code>## 
## Computed from 12000 by 430 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo   -377.1 16.1
## p_loo        78.5  5.2
## looic       754.1 32.2
## ------
## Monte Carlo SE of elpd_loo is 0.1.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     409   95.1%   1399      
##  (0.5, 0.7]   (ok)        21    4.9%   588       
##    (0.7, 1]   (bad)        0    0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>Let’s inspect the summary.
The within effect is estimated to be negative, but extremely small.
Also, the 95% CI includes zero, so we can’t be sure the effect is meaningful.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="analysis-study-1.html#cb112-1"></a><span class="kw">summary</span>(model8, <span class="dt">priors =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: well_being_state ~ 1 + social_media_subjective_hours_between + social_media_subjective_hours_within + (1 + social_media_subjective_hours_within | id) + (1 | day) 
##    Data: study1 (Number of observations: 430) 
## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Priors: 
## b_social_media_subjective_hours_between ~ normal(-0.2, 0.4)
## b_social_media_subjective_hours_within ~ normal(0, 0.4)
## Intercept ~ normal(3, 1)
## L ~ lkj_corr_cholesky(1)
## sd ~ student_t(3, 0, 2.5)
## sigma ~ student_t(3, 0, 2.5)
## 
## Group-Level Effects: 
## ~day (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.19      0.13     0.06     0.53 1.00     3110     4054
## 
## ~id (Number of levels: 95) 
##                                                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)                                           0.47      0.04     0.39     0.56 1.00     3855     6517
## sd(social_media_subjective_hours_within)                0.05      0.04     0.00     0.13 1.00     3339     4960
## cor(Intercept,social_media_subjective_hours_within)     0.25      0.46    -0.81     0.95 1.00     8922     5699
## 
## Population-Level Effects: 
##                                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept                                 3.24      0.14     2.96     3.52 1.00     3486     5266
## social_media_subjective_hours_between     0.00      0.03    -0.07     0.07 1.00     3690     5366
## social_media_subjective_hours_within     -0.03      0.03    -0.09     0.02 1.00    12799     8460
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.52      0.02     0.48     0.57 1.00     9673     8572
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
The effects plot (Figure <a href="analysis-study-1.html#fig:effects-model8-study1">4.66</a>) shows that the effect, if even there, is small at best.
<div class="figure"><span id="fig:effects-model8-study1"></span>
<img src="analysis_report_files/figure-html/effects-model8-study1-1.png" alt="Effects plot for Model 8" width="672" />
<p class="caption">
Figure 4.66: Effects plot for Model 8
</p>
</div>
</div>
<div id="model-9-accuracy-predicting-well-being" class="section level3">
<h3><span class="header-section-number">4.5.3</span> Model 9: Accuracy predicting well-being</h3>
<p>For this model, we ask whether the error people make in their estimation is related to their well-being on the state level.
As for as I know, there’s little prior knowledge we could build on for the relation between accuracy and well-being.</p>
<p>As for the specific priors:</p>
<ul>
<li>Like before, at perfect accuracy (0% error) and zero deviation I’ll assume a normal distribution centered on the midpoint of the scale (i.e., 3) with the intercept.
I’ll set the SD of that prior distribution to 1 once more.</li>
<li>As for the slopes: There’s one <a href="https://doi.org/10.1177/2050157920902830">paper</a> that correlated the absolute discrepancy between subjective and objective social media use and well-being indicators aggregated over a week.
They found a <span class="math inline">\(\beta\)</span> = .16 between log-transformed discrepancies and depression scores.
Discrepancy is a different measurement than the error that we calculated for accuracy.
Therefore, I’ll use a prior that’s centered on a negative relationship with a small SD.
Like above, I don’t expect that there will be large effects just based on the literature.
So I’ll assume a small effect (say -0.20 Likert-scales) with a somewhat wider standard deviation than in previous models (say 0.4).
This way, 95% of effects will be within -1 (-.20 + (2 times 0.3)) and 0.60 Likert-points on the outcome scale.
However, <code>error</code> is in percent, so we wouldn’t expect -.20 Likert-points with every one-percent increase.
Rather, I’d say the above effect is easier to specify for a standard deviation change in <code>error</code>, which is why I standardize <code>error</code>: one standard deviation increase in accuracy will be associated with, on average, a .20 lower score on well-being on the between level.</li>
<li>I have no information for the within-level, which is why I use a prior centered on zero with the same wide standard deviation.</li>
<li>For everything else, I’ll once more go with the default <code>brms</code> priors.</li>
</ul>
<p>Let’s set those priors and center at the same time.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="analysis-study-1.html#cb114-1"></a><span class="co"># standardize error</span></span>
<span id="cb114-2"><a href="analysis-study-1.html#cb114-2"></a>study1 &lt;-<span class="st"> </span></span>
<span id="cb114-3"><a href="analysis-study-1.html#cb114-3"></a><span class="st">  </span>study1 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb114-4"><a href="analysis-study-1.html#cb114-4"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb114-5"><a href="analysis-study-1.html#cb114-5"></a>    <span class="dt">error_s =</span> <span class="kw">scale</span>(error, <span class="dt">center =</span> <span class="ot">FALSE</span>, <span class="dt">scale =</span> <span class="ot">TRUE</span>)</span>
<span id="cb114-6"><a href="analysis-study-1.html#cb114-6"></a>  )</span>
<span id="cb114-7"><a href="analysis-study-1.html#cb114-7"></a></span>
<span id="cb114-8"><a href="analysis-study-1.html#cb114-8"></a><span class="co"># center to get between and within</span></span>
<span id="cb114-9"><a href="analysis-study-1.html#cb114-9"></a>study1 &lt;-<span class="st"> </span></span>
<span id="cb114-10"><a href="analysis-study-1.html#cb114-10"></a><span class="st">  </span>study1 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb114-11"><a href="analysis-study-1.html#cb114-11"></a><span class="st">  </span><span class="kw">group_by</span>(id) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb114-12"><a href="analysis-study-1.html#cb114-12"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb114-13"><a href="analysis-study-1.html#cb114-13"></a>    <span class="kw">across</span>(</span>
<span id="cb114-14"><a href="analysis-study-1.html#cb114-14"></a>      error_s,</span>
<span id="cb114-15"><a href="analysis-study-1.html#cb114-15"></a>      <span class="kw">list</span>(</span>
<span id="cb114-16"><a href="analysis-study-1.html#cb114-16"></a>        <span class="dt">between =</span> <span class="op">~</span><span class="st"> </span><span class="kw">mean</span>(.x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),</span>
<span id="cb114-17"><a href="analysis-study-1.html#cb114-17"></a>        <span class="dt">within =</span> <span class="op">~</span>.x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(.x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</span>
<span id="cb114-18"><a href="analysis-study-1.html#cb114-18"></a>      )</span>
<span id="cb114-19"><a href="analysis-study-1.html#cb114-19"></a>    )</span>
<span id="cb114-20"><a href="analysis-study-1.html#cb114-20"></a>  ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb114-21"><a href="analysis-study-1.html#cb114-21"></a><span class="st">  </span><span class="kw">ungroup</span>()</span>
<span id="cb114-22"><a href="analysis-study-1.html#cb114-22"></a></span>
<span id="cb114-23"><a href="analysis-study-1.html#cb114-23"></a><span class="co"># set priors</span></span>
<span id="cb114-24"><a href="analysis-study-1.html#cb114-24"></a>priors_model9 &lt;-<span class="st"> </span></span>
<span id="cb114-25"><a href="analysis-study-1.html#cb114-25"></a><span class="st">  </span><span class="kw">c</span>(</span>
<span id="cb114-26"><a href="analysis-study-1.html#cb114-26"></a>    <span class="co"># intercept</span></span>
<span id="cb114-27"><a href="analysis-study-1.html#cb114-27"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">3</span>, <span class="dv">1</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb114-28"><a href="analysis-study-1.html#cb114-28"></a>    </span>
<span id="cb114-29"><a href="analysis-study-1.html#cb114-29"></a>    <span class="co"># slopes for between</span></span>
<span id="cb114-30"><a href="analysis-study-1.html#cb114-30"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">0.4</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> <span class="st">&quot;error_s_between&quot;</span>),</span>
<span id="cb114-31"><a href="analysis-study-1.html#cb114-31"></a>    </span>
<span id="cb114-32"><a href="analysis-study-1.html#cb114-32"></a>    <span class="co"># slopes for between</span></span>
<span id="cb114-33"><a href="analysis-study-1.html#cb114-33"></a>    <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.40</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> <span class="st">&quot;error_s_within&quot;</span>)</span>
<span id="cb114-34"><a href="analysis-study-1.html#cb114-34"></a>  )</span></code></pre></div>
<p>And run the model.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="analysis-study-1.html#cb115-1"></a>model9 &lt;-<span class="st"> </span></span>
<span id="cb115-2"><a href="analysis-study-1.html#cb115-2"></a><span class="st">  </span><span class="kw">brm</span>(</span>
<span id="cb115-3"><a href="analysis-study-1.html#cb115-3"></a>    <span class="dt">data =</span> study1,</span>
<span id="cb115-4"><a href="analysis-study-1.html#cb115-4"></a>    <span class="dt">family =</span> gaussian,</span>
<span id="cb115-5"><a href="analysis-study-1.html#cb115-5"></a>    <span class="dt">prior =</span> priors_model9,</span>
<span id="cb115-6"><a href="analysis-study-1.html#cb115-6"></a>    well_being_state <span class="op">~</span></span>
<span id="cb115-7"><a href="analysis-study-1.html#cb115-7"></a><span class="st">      </span><span class="dv">1</span> <span class="op">+</span></span>
<span id="cb115-8"><a href="analysis-study-1.html#cb115-8"></a><span class="st">      </span>error_s_between <span class="op">+</span></span>
<span id="cb115-9"><a href="analysis-study-1.html#cb115-9"></a><span class="st">      </span>error_s_within <span class="op">+</span></span>
<span id="cb115-10"><a href="analysis-study-1.html#cb115-10"></a><span class="st">      </span>(</span>
<span id="cb115-11"><a href="analysis-study-1.html#cb115-11"></a>        <span class="dv">1</span> <span class="op">+</span></span>
<span id="cb115-12"><a href="analysis-study-1.html#cb115-12"></a><span class="st">        </span>error_s_within <span class="op">|</span></span>
<span id="cb115-13"><a href="analysis-study-1.html#cb115-13"></a><span class="st">        </span>id</span>
<span id="cb115-14"><a href="analysis-study-1.html#cb115-14"></a>      ) <span class="op">+</span></span>
<span id="cb115-15"><a href="analysis-study-1.html#cb115-15"></a><span class="st">      </span>(<span class="dv">1</span> <span class="op">|</span>day),</span>
<span id="cb115-16"><a href="analysis-study-1.html#cb115-16"></a>    <span class="dt">iter =</span> <span class="dv">5000</span>,</span>
<span id="cb115-17"><a href="analysis-study-1.html#cb115-17"></a>    <span class="dt">warmup =</span> <span class="dv">2000</span>,</span>
<span id="cb115-18"><a href="analysis-study-1.html#cb115-18"></a>    <span class="dt">chains =</span> <span class="dv">4</span>,</span>
<span id="cb115-19"><a href="analysis-study-1.html#cb115-19"></a>    <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb115-20"><a href="analysis-study-1.html#cb115-20"></a>    <span class="dt">seed =</span> <span class="dv">42</span>,</span>
<span id="cb115-21"><a href="analysis-study-1.html#cb115-21"></a>    <span class="dt">control =</span> <span class="kw">list</span>(</span>
<span id="cb115-22"><a href="analysis-study-1.html#cb115-22"></a>      <span class="dt">adapt_delta =</span> <span class="fl">0.999</span></span>
<span id="cb115-23"><a href="analysis-study-1.html#cb115-23"></a>    ),</span>
<span id="cb115-24"><a href="analysis-study-1.html#cb115-24"></a>    <span class="dt">file =</span> <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model9_study1&quot;</span>)</span>
<span id="cb115-25"><a href="analysis-study-1.html#cb115-25"></a>  )</span></code></pre></div>
Overall, the traceplots look fine and the chains seem to have mixed well, see (Figure <a href="#fig:inspect-model9-study1"><strong>??</strong></a>).
<div class="figure"><span id="fig:inspect-model9-study1-1"></span>
<img src="analysis_report_files/figure-html/inspect-model9-study1-1.png" alt="Traceplots and posterior distributions for Model 9" width="672" />
<p class="caption">
Figure 4.67: Traceplots and posterior distributions for Model 9
</p>
</div>
<div class="figure"><span id="fig:inspect-model9-study1-2"></span>
<img src="analysis_report_files/figure-html/inspect-model9-study1-2.png" alt="Traceplots and posterior distributions for Model 9" width="672" />
<p class="caption">
Figure 4.68: Traceplots and posterior distributions for Model 9
</p>
</div>
The posterior predictive checks (Figure <a href="analysis-study-1.html#fig:ppc-model9-study1">4.69</a>) look excellent (no surprise with only one predictor).
<div class="figure"><span id="fig:ppc-model9-study1"></span>
<img src="analysis_report_files/figure-html/ppc-model9-study1-1.png" alt="Posterior predictive checks for Model 9" width="672" />
<p class="caption">
Figure 4.69: Posterior predictive checks for Model 9
</p>
</div>
<p>Five cases are flagged as potentially influential, which is why we calculate ELPD directly.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="analysis-study-1.html#cb116-1"></a>model9_loo &lt;-<span class="st"> </span><span class="kw">loo</span>(model9, <span class="dt">reloo =</span> <span class="ot">TRUE</span>)</span>
<span id="cb116-2"><a href="analysis-study-1.html#cb116-2"></a><span class="kw">saveRDS</span>(model9_loo, <span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model9_loo_study1.rds&quot;</span>))</span></code></pre></div>
<p>When we calculate ELPD directly, all values appear unproblematic.
The results seem trustworthy.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="analysis-study-1.html#cb117-1"></a>model9_loo &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="kw">here</span>(<span class="st">&quot;models&quot;</span>, <span class="st">&quot;study1&quot;</span>, <span class="st">&quot;model9_loo_study1.rds&quot;</span>))</span>
<span id="cb117-2"><a href="analysis-study-1.html#cb117-2"></a>model9_loo</span></code></pre></div>
<pre><code>## 
## Computed from 12000 by 428 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo   -374.1 16.2
## p_loo        82.0  5.8
## looic       748.2 32.4
## ------
## Monte Carlo SE of elpd_loo is 0.2.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     410   95.8%   105       
##  (0.5, 0.7]   (ok)        18    4.2%   203       
##    (0.7, 1]   (bad)        0    0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>Let’s inspect the summary.
The within effect is estimated to be negative, but really small.
Also, the 95% CI includes zero and quite wide, so we can’t be sure the effect is meaningful.</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="analysis-study-1.html#cb119-1"></a><span class="kw">summary</span>(model9, <span class="dt">priors =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: well_being_state ~ 1 + error_s_between + error_s_within + (1 + error_s_within | id) + (1 | day) 
##    Data: study1 (Number of observations: 428) 
## Samples: 4 chains, each with iter = 5000; warmup = 2000; thin = 1;
##          total post-warmup samples = 12000
## 
## Priors: 
## b_error_s_between ~ normal(-0.2, 0.4)
## b_error_s_within ~ normal(0, 0.4)
## Intercept ~ normal(3, 1)
## L ~ lkj_corr_cholesky(1)
## sd ~ student_t(3, 0, 2.5)
## sigma ~ student_t(3, 0, 2.5)
## 
## Group-Level Effects: 
## ~day (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.19      0.14     0.06     0.54 1.00     2911     4398
## 
## ~id (Number of levels: 95) 
##                               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)                     0.47      0.04     0.39     0.56 1.00     3925     6136
## sd(error_s_within)                0.14      0.09     0.01     0.32 1.00     2465     4292
## cor(Intercept,error_s_within)     0.23      0.41    -0.69     0.92 1.00    10521     6541
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept           3.24      0.12     3.00     3.46 1.00     4895     4794
## error_s_between     0.00      0.07    -0.13     0.14 1.00     6769     7852
## error_s_within     -0.03      0.05    -0.14     0.07 1.00    12918     9224
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.52      0.02     0.48     0.56 1.00     8176     8667
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
The effects plot (Figure <a href="analysis-study-1.html#fig:effects-model9-study1">4.70</a>) shows that the effect, if even there, is small at best.
<div class="figure"><span id="fig:effects-model9-study1"></span>
<img src="analysis_report_files/figure-html/effects-model9-study1-1.png" alt="Effects plot for Model 9" width="672" />
<p class="caption">
Figure 4.70: Effects plot for Model 9
</p>
</div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="descriptives-and-visualizations-study-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="synthesis-study-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
